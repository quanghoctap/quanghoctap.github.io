---
title: 'Paper Explained 2: Pay Attention to MLPs'
date: 2024-02-02
categories: [Data Science, Deep Learning]
tags: [MLP, paper explained]
toc: true
math: true
publish: true
---

ğŸ“£ Attention Attention Attention, attention nÃ y attention kia, quÃ¡ nhiá»u attention. ğŸ˜… Trong bÃ i viáº¿t nÃ y chÃºng ta sáº½ cÃ¹ng tháº£o luáº­n vá» má»™t cÃ¡ch khÃ¡c cÅ©ng Ä‘Ã¡ng nháº­n Ä‘Æ°á»£c attention, máº·c dÃ¹ khÃ´ng pháº£i attention. ğŸ¤” Chá»§ Ä‘á» hÃ´m nÃ y cá»§a chÃºng ta sáº½ bÃ n vá» MLP (cá»¥ thá»ƒ hÆ¡n thÃ¬ lÃ  má»™t biáº¿n thá»ƒ cá»§a máº¡ng MLP truyá»n thá»‘ng) nÃ³i chung vÃ  gMLP nÃ³i riÃªng (Highlight cá»§a biáº¿n thá»ƒ nÃ y lÃ  Spatial Gating Unit - Má»™t Ä‘Æ¡n vá»‹ Ä‘á»ƒ kiá»ƒm soÃ¡t thÃ´ng tin). ğŸ¯ BÃ i [nÃ y](https://arxiv.org/pdf/2105.08050.pdf) khÃ¡ hay, cÃ¹ng Ä‘á»c nháº¿ !!! ğŸ“šğŸ‰

<!-- # Table of Contents

| Section | Description |
| ------- | ----------- |
| [Introduction](#giá»›i-thiá»‡u) | Introduction to the topic |
| [Installation](#installation) | Instructions for installation |
| [Usage](#usage) | How to use the software |
| [Contributing](#contributing) | Guidelines for contributing |
| [License](#license) | Information about the software license | -->


# Giá»›i thiá»‡u.
**!! NOTICE !!** Chá»¯ kiáº¿n trÃºc vá»›i chá»¯ mÃ´ hÃ¬nh nÃ³ hÆ¡i nháº¡y cáº£m má»i ngÆ°á»i, nÃªn trong bÃ i nÃ y, mÃ¬nh nÃ³i kiáº¿n trÃºc lÃ  nÃ³i chung, cÃ²n mÃ´ hÃ¬nh lÃ  nÃ³i cá»¥ thá»ƒ, chá»‰ Ä‘Ã­ch danh mÃ´ hÃ¬nh Ä‘Ã³ luÃ´n. z thui, cheers

CÃ¡c báº¡n mÃ  cÃ³ hay cáº­p nháº­t cÃ¡c thÃ´ng tin vá» máº¥y cÃ¡i mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLM) nhÆ° máº¥y cÃ¡i Mistral, LLaMa, v.v... thÃ¬ cháº¯c cÃ¡c báº¡n cÅ©ng Ä‘Ã£ biáº¿t cÃ¡i pháº§n cá»‘t lÃµi cá»§a máº¥y mÃ´ hÃ¬nh khá»§ng nÃ y lÃ  kiáº¿n trÃºc Transformer (mÃ  cá»¥ thá»ƒ hÆ¡n lÃ  cÆ¡ cháº¿ attention cá»§a nÃ³). 

Nhá»¯ng cÃ¡i kiáº¿n trÃºc cá»§a Transformer bao gá»“m 2 thÃ nh pháº§n chÃ­nh lÃ  Ä‘Ã³ lÃ  má»™t cÃ¡i **kiáº¿n trÃºc recurrent-free** (do Ä‘Ã³ mÃ  nÃ³ cho phÃ©p tÃ­nh cÃ¡i representation cá»§a cÃ¡c tokens má»™t cÃ¡ch song song) vÃ  khá»‘i **multi-head self-attention** cho phÃ©p Ä‘a dáº¡ng vÃ  tá»•ng há»£p thÃ´ng tin giá»¯a cÃ¡c token vá»›i nhau. 

Váº­y cÃ¢u há»i Ä‘áº·t ra á»Ÿ Ä‘Ã¢y lÃ : "**CÃ¡i khá»‘i attention Ä‘Ã³ cÃ³ cáº§n thiáº¿t khÃ´ng?**". Bá»Ÿi vÃ¬ xÃ©t theo má»™t máº·t nÃ o Ä‘Ã³, cÆ¡ cháº¿ attention cÃ³ má»™t cÃ¡i inductive bias Ä‘Ã³ lÃ  **tÆ°Æ¡ng tÃ¡c giá»¯a cÃ¡c token nÃªn Ä‘Æ°á»£c tham sá»‘ má»™t cÃ¡ch dynamic dá»±a trÃªn biá»ƒu diá»…n Ä‘áº§u vÃ o**, tá»©c lÃ  cÃ¡c cÃ¡i representation cÃ³ thá»ƒ thay Ä‘á»•i dá»±a trÃªn input cá»§a mÃ´ hÃ¬nh. NhÆ°ng xÃ©t theo máº·t khÃ¡c, dá»±a vÃ o Universal Approximation Theorem, báº¥t kÃ¬ cáº¥u trÃºc MLP nÃ o vá»›i cÅ©ng cÃ³ thá»ƒ **xáº¥p xá»‰ má»™t hÃ m nÃ o Ä‘Ã³ vá»›i tham sá»‘ cá»‘ Ä‘á»‹nh**. VÃ  tá»« nhá»¯ng suy nghÄ© trÃªn, mÃ¬nh cÃ³ thá»ƒ chuyá»ƒn cÃ¢u há»i vá»«a Ä‘áº·t ra sang má»™t cÃ¢u khÃ¡c cÅ©ng khÃ¡ tÆ°Æ¡ng tá»±: "**Äiá»u gÃ¬ Ä‘Ã³ng gÃ³p tá»›i thÃ nh cÃ´ng cá»§a mÃ´ hÃ¬nh hÆ¡n? Má»™t cÃ¡i inductive bias yáº¿u trong cÆ¡ cháº¿ attention hay kháº£ nÄƒng xáº¥p xá»‰ báº¥t ká»³ hÃ m toÃ¡n há»c nÃ o cá»§a cÃ¡c máº¡ng Neural?**"

ThÃ¬ bÃ i nghiÃªn cá»©u cá»§a cÃ¡c tÃ¡c giáº£, bÃªn cáº¡nh viá»‡c tráº£ lá»i cÃ¢u há»i á»Ÿ trÃªn, tÃ¡c giáº£ má»›i giá»›i thiá»‡u má»™t mÃ´ hÃ¬nh má»›i gá»i lÃ  gMLP bá»Ÿi vÃ¬ nÃ³ Ä‘Æ°á»£c táº¡o ra tá»« kiáº¿n trÃºc MLP vÃ  má»™t Ä‘Æ¡n vá»‹ cá»•ng (gating unit). 

VÃ  spoil trÆ°á»›c, nÃ³ hiá»‡u quáº£.

# Inductive bias (ThiÃªn kiáº¿n quy náº¡p)
Äá»ƒ dá»… hiá»ƒu hÆ¡n thÃ¬ má»i ngÆ°á»i tÆ°á»Ÿng tÆ°á»£ng: TrÆ°á»›c tá»›i giá» má»i ngÆ°á»i chá»‰ tháº¥y má»™t Ä‘Ã n thiÃªn nga Ä‘ang bÆ¡i trong má»™t cÃ¡i há»“ gáº§n nhÃ  thÃ´i, vÃ  Ä‘Ã¢y lÃ  nÆ¡i duy nháº¥t trong Ä‘á»i mÃ  má»i ngÆ°á»i cÃ³ thá»ƒ quan sÃ¡t máº¥y con thiÃªn nga nÃ y. Má»™t Ä‘á»‘ng giáº£ thuyáº¿t vá» máº¥y con thiÃªn nga nÃ y mÃ  cÃ¡c báº¡n cÃ³ thá»ƒ Ä‘áº·t ra nhÆ° sau: "ThiÃªn nga lÃ  loÃ i cÃ³ mÃ u tráº¯ng", "ThiÃªn nga chá»‰ biáº¿t bÆ¡i", "ThiÃªn nga khÃ´ng biáº¿t bay", "ThiÃªn nga Ä‘en khÃ´ng tá»“n táº¡i",v.v... NÃ³i chung lÃ  má»i ngÆ°á»i cÃ³ Ä‘Æ°a ra giáº£ thuyáº¿t nÃ o cÅ©ng Ä‘Æ°á»£c, do Ä‘Ã³ mÃ  cÃ³ vÃ´ sá»‘ giáº£ thuyáº¿t cÃ³ thá»ƒ Ä‘Æ°á»£c Ä‘Æ°a ra, Ä‘Ãºng hay sai lÃ  chuyá»‡n khÃ¡c. 

![swan](/assets/img/blog2/whitevsblack.png)

Theo lÃ½ thuyáº¿t, khÃ´ng gian giáº£ thuyáº¿t lÃ  vÃ´ táº­n (tá»©c lÃ  má»i ngÆ°á»i nghÄ© ra bao nhiÃªu cÃ¡i giáº£ thuyáº¿t cÅ©ng Ä‘Æ°á»£c, khÃ´ng giá»›i háº¡n, Ä‘Ãºng sai bÃ n sau). CÃ¡i inductive bias cÃ³ thá»ƒ Ä‘Æ°á»£c hiá»ƒu nhÆ° lÃ  cÃ¡c giáº£ thuyáº¿t Ä‘Æ°á»£c Æ°u tiÃªn hÆ¡n trong khÃ´ng gian giáº£ thuyáº¿t. Láº¥y vÃ­ dá»¥ nhÆ° máº¥y bÃ i toÃ¡n nhÆ° há»“i quy tuyáº¿n tÃ­nh, má»i ngÆ°á»i Ä‘ang giáº£ Ä‘á»‹nh tá»“n táº¡i má»‘i quan há»‡ tuyáº¿n tÃ­nh giá»¯a cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u, vÃ  báº±ng cÃ¡i giáº£ Ä‘á»‹nh nÃ y, má»i ngÆ°á»i Ä‘á»“ng thá»i giá»›i háº¡n khÃ´ng gian giáº£ thuyáº¿t xuá»‘ng cÃ²n má»‘i quan há»‡ tuyáº¿n tÃ­nh. 

![inductive_bias](/assets/img/blog2/inductive_bias.png)

Váº­y trong khuÃ´n khá»• cá»§a machine learning thÃ¬ Ä‘iá»u nÃ y lÃ  sao? Má»i ngÆ°á»i Ä‘ang cÃ³ Ä‘a dáº¡ng dá»¯ liá»‡u (áº£nh, chá»¯, tÃ­n hiá»‡u, v.v...) vÃ  vÃ´ vÃ n loáº¡i mÃ´ hÃ¬nh khÃ¡c nhau (tÃ­ch cháº­p, há»“i quy, v.v...) vÃ  má»—i mÃ´ hÃ¬nh khÃ¡c nhau nÃ y Ä‘á»u cÃ³ má»™t cÃ¡i inductive bias Ä‘á»ƒ nÃ³ hoáº¡t Ä‘á»™ng tá»‘t khÃ¡c nhau. VÃ­ dá»¥ nhÆ° lÃ  cÃ¡c máº¡ng CNN Ä‘Æ°á»£c xÃ¢y dá»±ng dá»±a trÃªn giáº£ thuyáº¿t cÃ¡c Ä‘iá»ƒm pixel náº±m gáº§n nhau thÃ¬ cÃ³ liÃªn quan tá»›i nhau vÃ  mÃ´ hÃ¬nh nÃªn há»c Ä‘Æ°á»£c cÃ¡i sá»± liÃªn quan nÃ y. 

VÃ  nhÃ¢n váº­t chÃ­nh cá»§a chÃºng ta lÃ  kiáº¿n trÃºc Transformer, mÃ´ hÃ¬nh nÃ y khÃ´ng cÃ³ má»™t cÃ¡i inductive bias máº¡nh, do Ä‘Ã³ cho phÃ©p mÃ´ hÃ¬nh khÃ¡i quÃ¡t hÃ³a tá»‘t hÆ¡n khi nÃ³ Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i nhiá»u dá»¯ liá»‡u hÆ¡n. LÃ­ do Ä‘Æ¡n giáº£n bá»Ÿi vÃ¬ **kiáº¿n trÃºc Transformer khÃ´ng Ä‘áº·t ra cÃ¡c giáº£ Ä‘á»‹nh vá» Ä‘áº§u vÃ o cá»§a mÃ´ hÃ¬nh**, mÃ  nÃ³ sáº½ há»c thÃ´ng qua cÆ¡ cháº¿ attention Ä‘á»ƒ biáº¿t cÃ¡c Ä‘áº§u vÃ o khÃ¡c nhau á»Ÿ cÃ¡c vá»‹ trÃ­ khÃ¡c nhau tÆ°Æ¡ng tÃ¡c nhÆ° tháº¿ nÃ o. CÃ¡c báº¡n cÃ³ thá»ƒ xem thÃªm cÃ¡c cÃ¡i giáº£i thÃ­ch cá»§a cÃ¡i inductive bias nÃ y á»Ÿ [Ä‘Ã¢y](https://towardsdatascience.com/the-inductive-bias-of-ml-models-and-why-you-should-care-about-it-979fe02a1a56) hoáº·c á»Ÿ [Ä‘Ã¢y](https://towardsdatascience.com/a-fairy-tale-of-the-inductive-bias-d418fc61726c)

# The Universal Approximation Theorem
CÃ³ má»™t bÃ i viáº¿t hay nÃ³i vá» chá»§ Ä‘á» nÃ y mÃ  má»i ngÆ°á»i cÃ³ thá»ƒ theo dÃµi thÃªm, mÃ¬nh Ä‘á»ƒ link á»Ÿ [Ä‘Ã¢y](https://medium.com/analytics-vidhya/you-dont-understand-neural-networks-until-you-understand-the-universal-approximation-theorem-85b3e7677126) nha. 

![neural_network](/assets/img/blog2/neuralnetwork.png)

NÃ³i Ä‘Æ¡n giáº£n thÃ¬ Ä‘á»‹nh lÃ­ nÃ y cho ráº±ng má»™t sá»‘ lÆ°á»£ng Ä‘áº¿m Ä‘Æ°á»£c cÃ¡c neuron trong cÃ¡i máº¡ng neuron cÃ³ thá»ƒ xáº¥p xá»‰ báº¥t kÃ¬ hÃ m liÃªn tá»¥c nÃ o vá»›i sá»± chÃ­nh xÃ¡c á»Ÿ má»™t má»©c Ä‘á»™ nÃ o Ä‘Ã³ (cháº¥p nháº­n sai sá»‘) vá»›i má»™t hÃ m kÃ­ch hoáº¡t nhÆ° Sigmoid hay ReLU hay má»™t hÃ m  nÃ o khÃ¡c.  

# CÃ¡ch mÃ´ hÃ¬nh hoáº¡t Ä‘á»™ng
TrÆ°á»›c khi tháº£o luáº­n thÃªm, trong bÃ i bÃ¡o gá»‘c, ngÆ°á»i ta cÃ³ dÃ¹ng 2 tá»« mÃ  láº§n Ä‘áº§u Ä‘á»c mÃ¬nh cÅ©ng chÆ°a hiá»ƒu rÃµ nhá»¯ng cÃ¡i Ä‘Ã³ lÃ  gÃ¬, Ä‘á»ƒ dá»… cáº¯t nghÄ©a hÆ¡n thÃ¬ á»Ÿ Ä‘Ã¢y mÃ¬nh giáº£i thÃ­ch lun:

- spatial: Má»i ngÆ°á»i cá»© hiá»ƒu lÃºc mÃ  nÃ³i cÃ¡i axis = 'spatial', tá»©c lÃ  ngÆ°á»i ta Ä‘ang Ä‘á» cáº­p Ä‘áº¿n khÃ´ng gian dÃ²ng trong cÃ¡i ma tráº­n.

- channel: ThÆ°á»ng má»i ngÆ°á»i nghe cÃ¡i channel nÃ y trong máº¥y cÃ¡i dáº¡ng bÃ i liÃªn quan Ä‘áº¿n áº£nh lÃ  nhiá»u, trong NLP, mÃ  cá»¥ thá»ƒ trong bÃ i nÃ y, khi nháº¯c tá»›i axis = 'channel', tá»©c lÃ  ngÆ°á»i ta Ä‘ang Ä‘á» cáº­p Ä‘áº¿n khÃ´ng gian cá»™t trong cÃ¡i ma tráº­n.

Láº¥y vÃ­ dá»¥ nhÆ° cÃ¡i cÃ¢u cá»§a mÃ¬nh Ä‘ang Ä‘Æ°á»£c biá»ƒu diá»…n dÆ°á»›i dáº¡ng má»™t ma tráº­n cÃ³ 50 dÃ²ng vÃ  512 cá»™t Ä‘i ha, thÃ¬ cÃ³ nghÄ©a cÃ¡i axis = 'spatial' sáº½ lÃ  cÃ¡i trá»¥c liÃªn quan Ä‘áº¿n khÃ´ng gian dÃ²ng, tá»©c lÃ  liÃªn quan Ä‘áº¿n sá»‘ 50, cÃ²n náº¿u axis = 'channel' sáº½ lÃ  cÃ¡i trá»¥c liÃªn quan Ä‘áº¿n khÃ´ng gian cá»™t, tá»©c liÃªn quan Ä‘áº¿n con sá»‘ 512, trong trÆ°á»ng há»£p mÃ¬nh vá»«a nÃªu, tá»©c lÃ  mÃ¬nh Ä‘ang cÃ³ 512 channel.

DÆ°á»›i Ä‘Ã¢y lÃ  cáº¥u trÃºc mÃ´ hÃ¬nh, mÃ¬nh sáº½ phÃ¢n tÃ­ch cá»¥ thá»ƒ tá»«ng thÃ nh pháº§n sau:


![gmlp_scheme](/assets/img/blog2/gmlp.png)

MÃ´ hÃ¬nh gMLP nÃ y khÃ¡ lÃ  cá»¥ thá»ƒ, nhÆ° hÃ¬nh trÃªn, má»i ngÆ°á»i cÃ³ thá»ƒ tháº¥y ráº±ng mÃ´ hÃ¬nh sáº½ bao gá»“m má»™t cÃ¡i chá»“ng gá»“m $L$ khá»‘i Ä‘Ã¨ lÃªn nhau vá»›i kÃ­ch thÆ°á»›c vÃ  cáº¥u trÃºc nhÆ° nhau vÃ  má»—i khá»‘i sáº½ Ä‘Æ°uá»c Ä‘á»‹nh nghÄ©a nhÆ° sau:

$$
Z = \sigma(XU), \quad \tilde{Z} = s(Z), \quad Y = \tilde{Z}V
$$

CÃ¡i $Z$ vá»›i cÃ¡i $Y$ vá» cÆ¡ báº£n lÃ  phÃ©p Channel Projection, cÃ²n cÃ¡i $\tilde{Z}$ lÃ  cÃ¡i Spatial Gating Unit, vá»›i Ä‘iá»ƒm nháº¥n cá»§a nÃ³ lÃ  phÃ©p Spatial Projection. 

Quan trá»ng nháº¥t trong 3 cÃ¡i cÃ´ng thá»©c á»Ÿ trÃªn Ä‘Ã³ lÃ  cÃ¡i á»Ÿ giá»¯a, chÃºng ta pháº£i thiáº¿t káº¿ lÃ m sao mÃ  $\tilde{Z}$ pháº£n Ã¡nh Ä‘Æ°á»£c sá»± tÆ°Æ¡ng tÃ¡c giá»¯a nhá»¯ng token trong cÃ¢u, nÃ³i má»™t cÃ¡ch khÃ¡c lÃ  pháº£i lÃ m sao Ä‘á»ƒ $s(\cdot)$ cho phÃ©p biáº¿n Ä‘á»•i tá»« $Z$ sang $\tilde{Z}$ trá»Ÿ nÃªn há»¯u dá»¥ng khi nÃ³ cho phÃ©p há»c Ä‘Æ°á»£c tÆ°Æ¡ng tÃ¡c giá»¯a cÃ¡c tokens trong cÃ¢u. 

LÆ°u Ã½ ráº±ng náº¿u $s(\cdot)$ lÃ  má»™t hÃ m Ã¡nh xáº¡ Ä‘á»“ng nháº¥t, cÃ¡i biáº¿n Ä‘á»•i á»Ÿ trÃªn trá»Ÿ thÃ nh má»™t cÃ¡i FFN thÃ´ng thÆ°á»ng (má»—i tokens Ä‘Æ°á»£c xá»­ lÃ­ Ä‘á»™c láº­p vá»›i nhau vÃ  khÃ´ng liÃªn quan vá»›i nhau). Do Ä‘Ã³ mÃ  thiáº¿t káº¿ $s(\cdot)$ sao cho nÃ³ há»c Ä‘Æ°á»£c tÆ°Æ¡ng tÃ¡c giá»¯a nhá»¯ng token trong cÃ¢u ráº¥t quan trá»ng Ä‘á»‘i vá»›i mÃ´ hÃ¬nh nÃ y. VÃ  cÃ¡ch mÃ  cÃ¡c tÃ¡c giáº£ Ä‘á» xuáº¥t Ä‘á»ƒ xÃ¢y dá»±ng cÃ¡i $s(\cdot)$ nÃ y lÃ  xem nÃ³ nhÆ° má»™t cÃ¡i spatial depthwise convolution (khÃ´ng biáº¿t dá»‹ch sao ğŸ¤¡)
## Channel Projection
Hiá»ƒu Ä‘Æ¡n giáº£n thÃ¬ channel projection chá»‰ lÃ  má»™t phÃ©p chiáº¿u thÃ´i má»i ngÆ°á»i, náº¿u má»i ngÆ°á»i Ã­t sá»­ dá»¥ng pytorch thÃ¬ nÃ³ lÃ  cÃ¡i `torch.nn.Linear(in_features, out_features)` Ã¡ má»i ngÆ°á»i. CÃ´ng thá»©c toÃ¡n cá»§a phÃ©p nÃ y lÃ  nhÆ° sau:

$$y = xA^T + b$$

Vá»›i x lÃ  ma tráº­n Ä‘áº§u vÃ o, A lÃ  ma tráº­n giÃºp Ã¡nh xáº¡ tá»« khÃ´ng gian cÃ³ cÃ¡i chiá»u Ä‘áº§u vÃ o lÃ  `in_features` sang chiá»u `out_features`. CÃ²n $b$ lÃ  bias

NÃªn lÃ  cÃ¡i paper nÃ y nÃ³i cao siÃªu váº­y chá»© cÃ¡i nÃ y Ä‘Æ¡n giáº£n lÃ  cÃ¡i MLP thÃ´i Ã  ğŸ¥¹

## Spatial Gating Unit
Spatial Gating Unit, hay gá»i nhanh SGU lÃ  má»™t khá»‘i cho phÃ©p mÃ´ hÃ¬nh gMLP nÃ y há»c Ä‘Æ°á»£c tÆ°Æ¡ng tÃ¡cc giá»¯a cÃ¡c token vá»›i nhau thÃ´ng qua má»™t phÃ©p chiáº¿u khÃ¡c bÃªn trong khá»‘i nÃ y, phÃ©p chiáº¿u nÃ y cÅ©ng Ä‘Æ¡n giáº£n lÃ  má»™t phÃ©p Ã¡nh xáº¡ tuyáº¿n tÃ­nh luÃ´n má»i ngÆ°á»i. NhÆ°ng khÃ´ng Ä‘Æ¡n giáº£n nhÆ° cÃ¡i channel projection, cÃ¡i nÃ y phÃ­a tÃ¡c giáº£ gá»i cÃ¡i khá»‘i Ä‘áº£m nhiá»‡m viá»‡c nÃ y lÃ  spatial projection. BÃªn cáº¡nh Ä‘Ã³ tÃ¡c giáº£ cÅ©ng Ä‘á» cáº­p thÃªm lÃ  cÃ¡i layer nÃ y sáº½ chá»©a má»™t cÃ¡i gá»i lÃ  **contraction operator** (theo mÃ¬nh tÃ¬m hiá»ƒu thÃ¬ cÃ¡i nÃ y lÃ  má»™t má»™t hÃ m Ã¡nh xáº¡ $T: V \mapsto V$ Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a bá»Ÿi $T(v) = kv$ vá»›i $k \in \mathbb{R}$ sao cho $k < 1$). VÃ  nhÆ° nhá»¯ng gÃ¬ Ä‘Ã£ Ä‘á» cáº­p vá» viá»‡c Ä‘Ã¢y lÃ  phÃ©p biáº¿n Ä‘á»•i tuyáº¿n tÃ­nh thÃ¬ nÃ³ cÃ³ cÃ´ng thá»©c nhÆ° sau:

$$
f_{W,b}(Z) = WZ + b
$$

Vá»›i $W \in \mathbb{R}^{n \times n}$ , trong Ä‘Ã³ n lÃ  chiá»u dÃ i cá»§a cÃ¢u nhÆ° há»“i nÃ£y mÃ¬nh Ä‘á» cáº­p Ã¡ má»i ngÆ°á»i. NhÆ° váº­y $W$ sáº½ lÃ  má»™t ma tráº­n vuÃ´ng Ã¡nh xáº¡ tá»« khÃ´ng gian n sang chÃ­nh khÃ´ng gian n, cÃ²n $b$ thÃ¬ lÃ  bias thÃ´i. 

Láº¥y vÃ­ dá»¥ nhÆ° náº¿u nhÆ° cÃ¡i cÃ¢u cá»§a mÃ¬nh cÃ³ 150 tokens nhÆ° nÃ£y Ä‘i ha, thÃ¬ ma tráº­n $W$ sáº½ cÃ³ kÃ­ch thÆ°á»›c lÃ  (150, 150). VÃ  khÃ´ng nhÆ° cÆ¡ cháº¿ self-attention cÃ³ tÃ­nh inductive bias yáº¿u, do Ä‘Ã³ mÃ  $W(Z)$ lÃ  khÃ´ng pháº£i má»™t biá»ƒu diá»…n linh hoáº¡t dá»±a vÃ o Ä‘áº§u vÃ o $Z$, mÃ  ma tráº­n Ã¡nh xáº¡ $W$ nÃ y sáº½ Ä‘á»™c láº­p khá»i biá»ƒu diá»…n Ä‘áº§u vÃ o.

NhÆ° váº­y mÃ  cÃ¡i layer $S(\cdot)$ sáº½ Ä‘Æ°á»£c biá»ƒu diá»…n dÆ°á»›i dáº¡ng cÃ´ng thá»©c nhÆ° sau:

$$s(Z) = Z \odot f_{W,b}(Z)$$

Vá»›i $\odot$ lÃ  phÃ©p nhÃ¢n hamdard (ai khÃ´ng quen chá»¯ nÃ y thÃ¬ hiá»ƒu lÃ  phÃ©p nhÃ¢n elemet-wise cÅ©ng Ä‘Æ°á»£c). 

ThÃ¬ khá»‘i nÃ y vá» cÆ¡ báº£n lÃ  xong rá»“i nha má»i ngÆ°á»i, tuy nhiÃªn cáº§n pháº£i lÆ°u Ã½ thÃªm vá» má»™t vÃ i Ä‘iá»u chá»‰nh cá»§a tÃ¡c giáº£. Äá»ƒ cho quÃ¡ trÃ¬nh huáº¥n luyá»‡n model nÃ³ á»•n Ä‘á»‹nh hÆ¡n, thÃ¬ Ä‘áº§u tiÃªn cÃ¡c tÃ¡c giáº£ Ä‘áº·t giÃ¡ trá»‹ khá»Ÿi táº¡o cá»§a ma tráº­n $W$ lÃ  cÃ¡c giÃ¡ trá»‹ xáº¥p xá»‰ giÃ¡ 0, trong khi Ä‘Ã³ Ä‘áº·t giÃ¡ trá»‹ cá»§a $b$ tháº³ng báº±ng 1, Ä‘iá»u nÃ y cÅ©ng Ä‘á»“ng nghÄ©a vá»›i viá»‡c $f_{W,b} \approx \mathbf{1}$, Ä‘iá»u nÃ y trá»±c tiáº¿p dáº«n tá»›i $s(Z) \approx Z$ á»Ÿ giai Ä‘oáº¡n Ä‘áº§u tiÃªn cá»§a quÃ¡ trÃ¬nh huáº¥n luyá»‡n, Ä‘áº£m báº£o ráº±ng má»—i khá»‘i gMLP sáº½ hoáº¡t Ä‘á»™ng nhÆ° má»™t cÃ¡i FFN (tá»©c lÃ  trong Ä‘Ã³ má»—i token Ä‘Æ°á»£c xá»­ lÃ­ Ä‘á»™c láº­p vá»›i nhau vÃ  má»‘i quan há»‡ giá»¯a cÃ¡c token Ä‘Ã³ sáº½ Ä‘Æ°á»£c cáº­p nháº­t thÃ´ng qua quÃ¡ trÃ¬nh huáº¥n luyá»‡n). VÃ  ngoÃ i ra báº±ng viá»‡c chia ma tráº­n $Z$ thÃ nh 2 ná»­a ($Z_1, Z_2$) thÃ¬ tÃ¡c giáº£ tháº¥y lÃ m váº­y nÃ³ thuáº­n tiá»‡n hÆ¡n (cháº¯c lÃ  theo thá»±c nghiá»‡m, mÃ¬nh khÃ´ng tháº¥y tÃ¡c giáº£ Ä‘á» cáº­p gÃ¬ vá» vá»¥ nÃ y ğŸ˜»), Ã  mÃ  chia 1 ná»­a á»Ÿ Ä‘Ã¢y lÃ  chia theo channel Ã¡ nha, vÃ­ dá»¥ nhÆ° Ä‘áº§u vÃ o Z cá»§a mÃ¬nh Ä‘ang lÃ  (150, 512) thÃ¬ lÃºc nÃ£y má»—i cÃ¡i $Z_1$, $Z_2$ sáº½ cÃ³ cÃ¡i kÃ­ch thÆ°á»›c lÃ  (150, 256). NhÆ° váº­y thÃ¬ cÃ¡i cÃ´ng thá»©c á»Ÿ trÃªn cÃ³ thá»ƒ ghi láº¡i nhÆ° dÆ°á»›i Ä‘Ã¢y:

$$s(Z) = Z_1 \odot f_{W,b}(Z_2)$$

ThÃ¬ nhÆ° Ä‘Ã£ Ä‘á» cáº­p lÃºc nÃ£y, ma tráº­n $W$ xáº¥p xá»‰ 0, thÃ¬ mÃ¬nh sáº½ cho cÃ¡c cÃ¡i value nÃ y Ä‘Æ°á»£c láº¥y tá»« má»™t cÃ¡i Uniform Distriution vá»›i cÃ¡i range gáº§n 0 nháº¥t cÃ³ thá»ƒ, vÃ  váº½ nÃ³ báº±ng heatmap thÃ¬ nÃ³ ra Ä‘Æ°á»£c cÃ¡i hÃ¬nh nÃ y:

![init_weight_matrix](/assets/img/blog2/init_weight_matrix.png)

Má»¥c Ä‘Ã­ch náº±m á»Ÿ ma tráº­n vuÃ´ng $W$ sáº½ há»c Ä‘Æ°á»£c cÃ¡c tÆ°Æ¡ng tÃ¡c cÃ³ Ã½ nghÄ©a giá»¯a cÃ¡c token. Äá»ƒ hiá»ƒu rÃµ hÆ¡n nÃ³ lÃ  ra sao thÃ¬ má»i ngÆ°á»i nhÃ¬n thá»­ cÃ¡i hÃ¬nh dÆ°á»›i Ä‘Ã¢y: 

![weight_matrix_4h](/assets/img/blog2/weight_matrix.png)

Trong lÃºc cháº¡y code, mÃ¬nh cÃ³ Ä‘á»ƒ cÃ¡i head = 4 nÃªn vá» cÆ¡ báº£n thÃ¬ mÃ¬nh sáº½ cÃ³ 4 cÃ¡i ma tráº­n $W$ rá»“i cÃ³ gÃ¬ sau nÃ y mÃ¬nh gom 4 cÃ¡i head vÃ´ thÃ nh 1 cÃ¡i head lÃ  Ä‘Æ°á»£c. ThÃ¬ vá» cÆ¡ báº£n, 4 cÃ¡i head nÃ y lÃ  cá»‘ Ä‘á»‹nh, chá»© nÃ³ khÃ´ng cÃ³ dynamic nhÆ° cÃ¡i cÆ¡ cháº¿ attention.

ThÃ¬ á»Ÿ Ä‘Ã¢y lÃ  Ä‘ang sá»­ dá»¥ng 4 head, vá» sau thÃ¬ sáº½ gá»™p láº¡i lÃ m 1 head thÃ´i, Ä‘Æ¡n giáº£n nháº¥t mÃ  ai cÅ©ng nghÄ© tá»›i khi gá»™p 4 head thÃ nh 1 head thÃ¬ lÃ  sá»­ dá»¥ng tÃ­nh trung bÃ¬nh, cá»© cá»™ng cáº£ 4 cÃ¡i head láº¡i xong rá»“i chia 4, thÃ¬ ra Ä‘Æ°á»£c cÃ¡i ma tráº­n $W$ sau Ä‘Ã¢y:

![avg_weight_matrix_1h](/assets/img/blog2/avg_weight_matrix.png)

NgoÃ i ra bÃªn phÃ­a tÃ¡c giáº£ cÅ©ng cÃ³ káº¿t há»£p thÃªm cÃ¡i cÆ¡ cháº¿ attention vÃ´ trong máº¥y cÃ¡i khá»‘i nÃ y, thÃ¬ há» Ä‘Æ°á»£c káº¿t quáº£ nhÆ° dÆ°á»›i Ä‘Ã¢y:

![weight_attention_matrix](/assets/img/blog2/gmlp_attention_matrix.png)

## ToÃ n bá»™ cáº¥u trÃºc mÃ´ hÃ¬nh

Biá»ƒu diá»…n Ä‘áº§u vÃ o (a.k.a input embeddings) sáº½ lÃ  má»™t ma tráº­n cÃ³ kÃ­ch thÆ°á»›c  $x \in \mathbb{R}^{n \times d}$ vá»›i $n$ lÃ  Ä‘á»™ dÃ i cá»§a cÃ¢u vÃ  $d$ lÃ  chiá»u cá»§a vector biá»ƒu diá»…n. 

Sau Ä‘Ã³ ma tráº­n biá»ƒu diá»…n nÃ y sáº½ Ä‘Æ°á»£c chuáº©n hÃ³a (cÃ¡ch thá»©c chuáº©n hÃ³a sáº½ lÃ  chuáº©n hÃ³a theo axis = 'channel'). Chuáº©n hÃ³a á»Ÿ Ä‘Ã¢y sáº½ lÃ  chuáº©n hÃ³a theo layer, náº¿u ai chÆ°a sá»­ dá»¥ng cÃ¡i nÃ y trong pytorch thÃ¬ nÃ³ lÃ  `torch.nn.LayerNorm` nha má»i ngÆ°á»i, vá» cÆ¡ báº£n thÃ¬ cÃ´ng tá»©c toÃ¡n cá»§a cÃ¡i nÃ y nhÆ° sau:

$$y = \frac{(x - E[x]) \cdot \gamma}{\sqrt{Var[x] + \epsilon}} + \beta$$

CÃ¡i nÃ y mÃ  giáº£i thÃ­ch nhanh thÃ¬ nÃ³ kiá»ƒu nhÆ° lÃ  giÃ¡ trá»‹ Ä‘áº§u vÃ o cá»§a táº¥t cáº£ neuron trong cÃ¹ng má»™t layer Ä‘Æ°á»£c chuáº©n hÃ³a cho tá»«ng diá»ƒm dá»¯ liá»‡u.

VÃ  káº¿ Ä‘áº¿n sau Ä‘Ã³, ma tráº­n Ä‘Æ°á»£c tráº£ ra tá»« bÆ°á»›c chuáº©n hÃ³a sáº½ Ä‘Æ°á»£c chiáº¿u qua má»™t khÃ´ng gian khÃ¡c. BÆ°á»›c chiáº¿u nÃ y khÃ¡ Ä‘Æ¡n giáº£n thÃ´i má»i ngÆ°á»i, cá»© tÆ°á»Ÿng tÆ°á»£ng nÃ³ lÃ  má»™t hÃ m toÃ¡n nhÆ° kiá»ƒu $f: \mathbb{R}^{150 \times 512} \rightarrow \mathbb{R}^{150 \times 256}$, hiá»ƒu nhÆ° váº­y thÃ¬ nÃ³ chÃ­nh lÃ  phÃ©p `nn.Linear()` trong pytorch luÃ´n. 

Sau Ä‘Ã³ ma tráº­n má»›i nÃ y sáº½ Ä‘i qua má»™t hÃ m kÃ­ch hoáº¡t nÃ o Ä‘Ã³, cÃ³ thá»ƒ lÃ  hÃ m ReLU hay GeLU hay gÃ¬ gÃ¬ Ä‘áº¥y, nhÆ° váº­y thÃ¬ ta cÃ³ thá»ƒ biá»ƒu diá»…n dÆ°á»›i cÃ´ng thá»©c toÃ¡n há»c tá»« sau bÆ°á»›c normalize nhÆ° sau:

$$
Z = \sigma(XU)
$$

Vá»›i X lÃ  Ä‘áº§u vÃ o, U lÃ  má»™t ma tráº­n cho phÃ©p Ã¡nh xáº¡ X sang má»™t khÃ´ng gian cÃ³ sá»‘ chiá»u khÃ¡c, cÃ²n $\sigma$ lÃ  má»™t hÃ m kÃ­ch hoáº¡t phi tuyáº¿n nÃ o Ä‘Ã³ nhÆ° nÃ£y mÃ¬nh nÃ³i. ThÃ¬ pháº§n nÃ y chá»‰ lÃ  khÃºc Channel Projection thÃ´i chá»© khÃ´ng gÃ¬ má»›i Ã¡ ae. 

Rá»“i cÃ¡i $Z$ nÃ y sáº½ Ä‘i qua cÃ¡i Spatial Gating Unit á»Ÿ trÃªn rá»“i láº¡i Ä‘i qua má»™t cÃ¡i Channel Projection ná»¯a Ä‘á»ƒ nÃ³ vá» láº¡i cÃ¹ng chiá»u vá»›i cÃ¡i d_model lÃºc Ä‘áº§u. 

VÃ  á»Ÿ phÃ­a cuá»‘i cÃ¹ng nÃ y, cÃ¡c token (trong trÆ°á»ng há»£p text) hoáº·c cÃ¡c patches (trong trÆ°á»ng há»£p áº£nh) Ä‘Ã£ há»c Ä‘Æ°á»£c sá»± tÆ°Æ¡ng tÃ¡c cá»§a nhau rá»“i, vÃ  nhÆ° nÃ£y mÃ¬nh nÃ³i Ã¡, cÃ¡i ma tráº­n $W$ lÃ  Ä‘á»™c láº­p vá»›i cÃ¡i Ä‘áº§u vÃ o, nÃªn lÃ  nÃ³ khÃ´ng cÃ³ dynamic nhÆ° cÃ¡i cÆ¡ cháº¿ attention. VÃ  hy vá»ng lÃ  ma tráº­n nÃ y cÃ³ thá»ƒ xáº¥p xá»‰ má»™t hÃ m nÃ o Ä‘Ã³ (theo nhÆ° Universal Approximation Theorem).

LÃºc nÃ y thÃ¬ má»i ngÆ°á»i thÃªm cÃ¡i Ä‘áº§u Ä‘á»ƒ lÃ m classification hay lÃ  generation gÃ¬ cÅ©ng Ä‘Æ°á»£c, lÃºc nÃ y thÃ¬ tÃ¹y ngÆ°á»i thiáº¿t káº¿ thÃ´i

# á»¨ng dá»¥ng
CÃ¡i nÃ y thÃ¬ vÃ´ vÃ n á»©ng dá»¥ng luÃ´n anh em, trong paper thÃ¬ ngÆ°á»i ta á»©ng dá»¥ng cáº£ trong Vision, cáº£ trong NLP. Do post trÆ°á»›c lÃ m Text Classfication rá»“i nÃªn post nÃ y mÃ¬nh miÃªu táº£ rÃµ hÆ¡n cÃ¡i Image Classification ha, nhÆ°ng mÃ  code mÃ¬nh cÃ³ Ä‘á»ƒ trong github rá»“i, má»i ngÆ°á»i cÃ³ thá»ƒ tham kháº£o thÃªm á»Ÿ [Ä‘Ã¢y](https://github.com/ngnquanq/blog/blob/main/Pay%20attentions%20to%20MLP/main.ipynb).

á» thá»i Ä‘iá»ƒm Ä‘Ã³, cÃ¡c tÃ¡c giáº£ thá»±c hiá»‡n phÃ¢n tÃ­ch hiá»‡u quáº£ cá»§a gMLP trong lÄ©nh vá»±c Computer Vision, cá»¥ thá»ƒ hÆ¡n lÃ  vá»›i task Image Classification trÃªn táº­p ImageNet (khÃ´ng sá»­ dá»¥ng thÃªm data tá»« bÃªn ngoÃ i) nhÆ°ng mÃ  do bá»™ nÃ y náº·ng so vá»›i mÃ¡y mÃ¬nh nÃªn mÃ¬nh sáº½ pick má»™t bá»™ khÃ¡c gpu friendly hÆ¡n aka CIFAR10. Bá»™ nÃ y thÃ¬ náº·ng khoáº£ng 162Mb náº¿u mÃ¬nh nhá»› khÃ´ng láº§m, cÅ©ng 50.000 áº£nh train vÃ  10.000 áº£nh text, má»—i áº£nh cÃ³ kÃ­ch thÆ°á»›c $32 \times 32$ vÃ  lÃ  áº£nh mÃ u vá»›i 3 kÃªnh mÃ u rgb, vá» class thÃ¬ cÃ³ 10 class khÃ¡c nhau

Trong bÃ i nÃ y thÃ¬ cÃ¡c tÃ¡c giáº£ sá»­ dá»¥ng Ä‘áº§u vÃ o vá»›i Ä‘áº§u ra nhÆ° cÃ¡i protocol cá»§a mÃ´ hÃ¬nh [ViT/16](https://arxiv.org/pdf/2010.11929.pdf) cho cáº£ input láº«n output. NÃªn lÃ  mÃ¬nh cÅ©ng lÃ m váº­y, nhÆ°ng mÃ  cÃ¡i hÃ¬nh nÃ y cÃ³ $32 \times 32$ Ã  nÃªn chia 4 khÃºc $16 \times 16$ thÃ¬ nhÃ¬n kÃ¬ kÃ¬ nÃªn mÃ¬nh chia nÃ³ thÃ nh 16 khÃºc $8 \times 8$ nhÃ¬n cho nÃ³ bá»›t kÃ¬ =)))))))))))))). Vá» batch size thÃ¬ mÃ¬nh Ä‘á»ƒ thÃ nh 32, cÃ¡c phÆ°Æ¡ng phÃ¡p augmentation thÃ¬ chá»‰ dÃ¹ng normalize bÃ¬nh thÆ°á»ng thÃ´i, hÃ m loss dÃ¹ng Cross Entropy Loss, optimizer thÃ¬ dÃ¹ng AdamW. 

Trong code mÃ¬nh Ä‘á»ƒ trÃªn github lÃ  cÃ¡i mÃ´ hÃ¬nh lightweight, Ä‘Ã¢u Ä‘Ã³ cá»¡ 4M tham sá»‘. ThÃ¬ con sá»‘ nÃ y lÃ  train dá»… dÃ ng trÃªn mÃ¡y local má»i ngÆ°á»i nha. LÆ°u Ã½ thÃªm lÃ  mÃ¬nh cÃ³ thá»­ vá»›i mÃ´ hÃ¬nh nÃ y vá»›i 51M tham sá»‘ trÃªn con NVIDIA RTX 3090 (thuÃª cloud gpu chá»© Ä‘Ã o Ä‘Ã¢u ra ğŸ¥¹) thÃ¬ cháº¡y 10 epoch Ä‘Ã¢u Ä‘Ã³ cá»¡ 15 phÃºt, vÃ  mÃ´ hÃ¬nh nÃ y há»™i tá»¥ trÃªn táº­p train ráº¥t nhanh (trong khi vá»›i 4M nhÆ° trÃªn github thÃ¬ khÃ´ng nhanh nhÆ° váº­y). CÃ¡i mÃ¬nh muá»‘n nÃ³i Ã¡ lÃ  top1-acc cá»§a mÃ´ hÃ¬nh 51M sau 10 epoch lÃ  cá»¡ 70% cho táº­p test vÃ  95% cho táº­p train, trong khi vá»›i mÃ´ hÃ¬nh 4M thÃ¬ khÃ´ng Ä‘Æ°á»£c nhÆ° váº­y. NÃªn lÃ  (nÃ³i cÃ¡i nÃ y hÆ¡i thá»«a) viá»‡c mÃ´ hÃ¬nh cÃ ng lá»›n (theo nhÆ° tÃ¡c giáº£ xÃ¡c nháº­n) thÃ¬ kháº£ nÄƒng mÃ´ hÃ¬nh há»c cÅ©ng cÃ ng lá»›n, nÃ³i nÃ´m na lÃ  kháº£ nÄƒng cá»§a mÃ´ hÃ¬nh scale theo Ä‘á»™ lá»›n cá»§a mÃ´ hÃ¬nh. Ã€ mÃ  thuÃª GPU nhÆ° con NVIDIA RTX 3090 lÃ  16k/h nha, nhÆ° kiá»ƒu thuÃª phÃ²ng net (phÃ²ng cyber háº³n hoi). MÃ¬nh thuÃª á»Ÿ [Ä‘Ã¢y](https://thuegpu.vn/), cá»±c kÃ¬ phÃ¹ há»£p cho ae nÃ o cÃ³ máº¥y model nÃ³ náº·ng vcl mÃ  cháº¡y trÃªn colab nÃ³ hÆ¡i Ä‘uá»“i. 

ThÃ¬ do lÃ  protocol y chang, nÃªn lÃ  má»™t lá»›n chia thÃ nh máº¥y patch nhá» hÆ¡n, nhÃ¬n nhÆ° cÃ¡i hÃ¬nh nÃ y: 

![patches](/assets/img/blog2/patches.png)

Ok, giá» vÃ´ nhÃ¢n váº­t tiÃªu Ä‘iá»ƒm, lÃ  cÃ¡i Spatial Gating Unit, code cá»§a nÃ³ nhÆ° sau:

```python
class SpatialGatingUnit(nn.Module):
    def __init__(self, d_ffn, 
                 seq_len, weight_value=0.05):
        super().__init__()
        self.norm = nn.LayerNorm(d_ffn//2)
        
        # Setup weight for the spatial projection
        self.weight = nn.Parameter(torch.zeros(seq_len,seq_len))
        nn.init.uniform_(self.weight, a=-weight_value, b=weight_value)
        
        # Setup bias for the spatial projection
        self.bias = nn.Parameter(torch.ones(seq_len))

    def forward(self, x):
        u, v = x.chunk(2, dim=-1)
        v = self.norm(v)
        
        weight, bias = self.weight, self.bias
        v = einsum('b n d, m n -> b m d', v, weight) + rearrange(bias, 'n -> () n ()')
        return u * v
```
PhÃ¢n biá»‡t rÃµ cÃ¡i d_model lÃ  cÃ¡i embedding dim, cÃ²n cÃ¡i d_ffn lÃ  cÃ¡i dim cá»§a cÃ¡i channel projection nha má»i ngÆ°á»i, cÃ²n seq_len thÃ¬ dÃ¹ng chung, hoáº·c lÃ  token, hoáº·c lÃ  patches.

Giá» tá»›i má»™t block gMLP sáº½ nhÃ¬n tháº¿ nÃ y:
```python
class gMLPBlock(nn.Module):
    def __init__(self, d_model, d_ffn, seq_len):
        super().__init__()
        self.norm = nn.LayerNorm(d_model)
        self.channel_proj_U = nn.Sequential(
            nn.Linear(d_model, d_ffn),
            nn.GELU()
        )
        self.sgu = SpatialGatingUnit(d_ffn, seq_len)
        self.channel_proj_V = nn.Sequential(
            nn.Linear(d_ffn//2, d_model),
            nn.GELU()
        )
        
    def forward(self, x):
        res = x
        x = self.norm(x)
        x = self.channel_proj_U(x)
        x = self.sgu(x)
        x = self.channel_proj_V(x)
        return x + res
```

ÄÃ³, nhÆ° nÃ£y giá» mÃ¬nh Ä‘á» cáº­p á»Ÿ trÃªn thÃ´i, váº­y thÃ¬ má»™t khá»‘i gMLP hÃ²an chá»‰nh thÃ¬ nhÃ¬n nhÆ° nÃ y:
```python
class gMLP(nn.Module):
    def __init__(self, d_model, d_ffn, seq_len, num_layers):
        super().__init__()
        self.layers = nn.ModuleList([])
        for _ in range(num_layers):
            self.layers.append(gMLPBlock(d_model, d_ffn, seq_len))
            
    def forward(self, x):
        for layer in self.layers:
            x = layer(x)
        return x
```
Vá» cÃ¡i pháº§n tÃ¡ch hÃ¬nh ra thÃ nh cÃ¡c patch sáº½ Ä‘Æ°á»£c viáº¿t nhÆ° nÃ y:
```python
class PatchEmbedding(nn.Module):
    def __init__(self, patch_size, in_channels, embed_dim):
        super().__init__()
        self.proj = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)

    def forward(self, x):
        x = self.proj(x)  # (B, embed_dim, H, W)
        return x.flatten(2).transpose(1, 2)  # (B, num_patches, embed_dim)
```
Vá» pháº§n quan trá»ng nháº¥t cá»§a cÃ¡i task phÃ¢n loáº¡i áº£nh nÃ y lÃ  cÃ¡i model Ä‘á»ƒ tráº£ ra cÃ¡i embedding mÃ  á»Ÿ Ä‘Ã³ cÃ¡c token (hoáº·c patch) Ä‘Ã£ cÃ³ Ä‘Æ°á»£c thÃ´ng tin cá»§a nhau, thÃ¬ Ä‘Æ°á»£c code tháº¿ nÃ y:
```python
class gMLP_Vision(nn.Module):
    def __init__(self, patch_size = 8, num_patches = 16, embed_dim = 768, num_layers = 6):
        super().__init__()
        self.patch_embed = PatchEmbedding(patch_size=patch_size, in_channels=3, embed_dim=embed_dim)
        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))
        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, embed_dim))
        self.pos_drop = nn.Dropout(p=0.1)

        self.blocks = gMLP(d_model=embed_dim,
                           d_ffn=embed_dim*4, 
                           seq_len=num_patches+1, 
                           num_layers=num_layers)

        self.norm = nn.LayerNorm(embed_dim)

    def forward(self, x):
        B, C, H, W = x.shape
        x = self.patch_embed(x)

        cls_tokens = self.cls_token.expand(B, -1, -1)
        x = torch.cat((cls_tokens, x), dim=1)
        x = x + self.pos_embed
        x = self.pos_drop(x)

        x = self.blocks(x)

        x = self.norm(x)

        return x[:, 0]
```
Ok, cuá»‘i cÃ¹ng thÃ¬ mÃ¬nh cáº§n 1 cÃ¡i head Ä‘á»ƒ phÃ¢n loáº¡i áº£nh, cÃ¡i nÃ y lÃ m Ä‘Æ¡n giáº£n thÃ´i ae, thÃ¬ nÃ³ nhÆ° sau:
```python
class Image_Classification(nn.Module):
    def __init__(self, patch_size = 8, num_patches = 16, embed_dim = 512, 
                 num_layers = 3, fc_dim = 256, num_classes = 10):
        super().__init__()
        self.model = gMLP_Vision(patch_size=patch_size, num_patches=num_patches, embed_dim=embed_dim, num_layers=num_layers)
        self.fc_1 = nn.Linear(embed_dim, fc_dim)
        self.act = nn.GELU()
        self.head = nn.Linear(fc_dim, num_classes)

    def forward(self, x):
        x = self.model(x)
        x = self.fc_1(x)
        x = self.act(x)
        x = self.head(x)
        return x
```
CÃ²n code Ä‘á»ƒ cháº¡y cÃ¡i accuracy thÃ¬ nÃ³ nhÆ° nÃ y:
```python
def evaluate_epoch_topk(model, test_dataloader, device, k):
    model.eval()
    correct = 0
    total = 0

    with torch.no_grad():
        for idx, (inputs, labels) in enumerate(test_dataloader):
            inputs = inputs.to(device)
            labels = labels.to(device)

            predictions = model(inputs)

            _, predicted = predictions.topk(k, 1, True, True)
            total += labels.size(0)
            correct += (predicted == labels.view(-1, 1).expand_as(predicted)).sum().item()

    topk_acc = correct / total
    return topk_acc

for i in range(1,6):
  topk = evaluate_epoch_topk(model, testloader, device, i)
  print(f"Top-{i} accuracy: {topk:.2f}")
```
CÃ²n pháº§n preprocess vá»›i download áº£nh thÃ¬ lÃ m nhÆ° torchvision hÆ°á»›ng dáº«n thÃ´i, má»i ngÆ°á»i cÃ³ thá»ƒ lÃªn Ä‘Ã³ coi thá»­.

# Tháº£o luáº­n thÃªm
Äáº§u tiÃªn thÃ¬ blog nÃ y cÃ³ pháº§n phÃ¢n tÃ­ch Æ°u nhÆ°á»£c Ä‘iá»ƒm ná»¯a, nhÆ°ng mÃ¬nh tháº¥y bÃ i nÃ y khÃ´ng nÃªn Ä‘áº·t ra Æ°u vá»›i nhÆ°á»£c Ä‘iá»ƒm. Quay láº¡i vá»›i Ã½ nghÄ©a cá»§a bÃ i nghiÃªn cá»©u nÃ y, má»¥c Ä‘Ã­ch chÃ­nh cá»§a bÃ i nÃ y khÃ´ng pháº£i lÃ  Ä‘á» xuáº¥t ra má»™t mÃ´ hÃ¬nh má»›i, má»™t cáº¥u trÃºc má»›i. MÃ  lÃ  Ä‘á»ƒ láº­t láº¡i cÃ¢u há»i vá» sá»± cáº§n thiáº¿t cá»§a khá»‘i attention.

LÃ½ do mÃ¬nh thÃ­ch bÃ i nÃ y lÃ  vÃ¬ nÃ³ Ä‘áº·t ra má»™t gÃ³c nhÃ¬n má»›i cho má»™t váº¥n Ä‘á» nhÃ¬n cÃ³ váº» cÅ©, tá»« Ä‘Ã³ lÃ m má»›i váº¥n Ä‘á». Viá»‡c tÃ¡ch tÃ­nh hiá»‡u quáº£ cá»§a cáº¥u trÃºc Transformer ra thÃ nh tÃ­nh cháº¥t yáº¿u trong cÃ¡i inductive bias cá»§a cÃ´ng thá»©c attention vÃ  kháº£ nÄƒng xáº¥p xá»‰ má»™t cÃ¡i arbitrary function nÃ o Ä‘Ã³ lÃªn bÃ n cÃ¢n cÅ©ng khÃ¡ má»›i máº». NÃªn mÃ¬nh thÃ­ch =))))))

Äiá»u nÃ y cho tháº¥y ráº±ng attention might not what we all needed. CÃ³ thá»ƒ vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p cÅ© hÆ¡n mÃ  mÃ¬nh attention vÃ o nÃ³ thÃ¬ váº«n cÃ³ thá»ƒ cho ra cÃ¡c káº¿t quáº£ ráº¥t tuyá»‡t vá»i. VÃ  cÃ³ thá»ƒ tháº¥y ráº±ng vá»›i cÃ¡i quadratic complexity thÃ¬ nhá»¯ng mÃ´ hÃ¬nh sá»­ dá»¥ng cÃ¡i cÆ¡ cháº¿ attention khÃ¡ lÃ  trá»Ÿ nÃªn tá»‘n kÃ©m khi input Ä‘áº§u vÃ o to hÆ¡n, hoáº·c dÃ i hÆ¡n. ThÃ¬ nÃ³i chung lÃ  váº­y, cÃ³ thá»ƒ sau nÃ y mÃ¬nh ngáº«m ra gÃ¬ Ä‘Ã³ hay hÆ¡n thÃ¬ mÃ¬nh bá» vÃ´ Ä‘Ã¢y sau váº­y.

ğŸ»ğŸ»ğŸ» !!! Cheers !!! ğŸ»ğŸ»ğŸ»

# References

1. [Pay Attention to MLPs](https://arxiv.org/pdf/2105.08050.pdf)

2. [The Inductive Bias of ML Models, and Why You Should Care About It](https://towardsdatascience.com/the-inductive-bias-of-ml-models-and-why-you-should-care-about-it-979fe02a1a56)

3. [A fAIry tale of the Inductive Bias](https://towardsdatascience.com/a-fairy-tale-of-the-inductive-bias-d418fc61726c) (nÃ y lÃ  ngÆ°á»i ta ghi chá»¯ fairy v Ã¡ nha ae, cháº¯c chÆ¡i chá»¯)

4. [You Donâ€™t Understand Neural Networks Until You Understand the Universal Approximation Theorem](https://medium.com/analytics-vidhya/you-dont-understand-neural-networks-until-you-understand-the-universal-approximation-theorem-85b3e7677126)

5. [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html)

6. [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929)

