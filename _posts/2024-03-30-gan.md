---
title: 'Paper Explained 4: Generative Adversarial Nets'
date: 2024-03-30
categories: [Data Science, Deep Learning]
tags: [gan, paper explained]
toc: true
math: true
publish: true
---

GAN lÃ  má»™t trong nhá»¯ng framework má»›i vÃ  tháº­t sá»± Ä‘á»™t phÃ¡ trong viá»‡c Æ°á»›c lÆ°á»£ng má»™t mÃ´ hÃ¬nh táº¡o sinh thÃ´ng qua quÃ¡ trÃ¬nh Ä‘á»‘i ngáº«u. Vá»›i Ã½ kiáº¿n cÃ¡ nhÃ¢n cá»§a mÃ¬nh thÃ¬ Ä‘Ã¢y lÃ  paper hay vÃ  khÃ¡ phá»©c táº¡p, vá»›i mÃ¬nh thÃ¬ paper nÃ y lÃ  mÃ´ hÃ¬nh generative Ä‘áº§u tiÃªn mÃ  mÃ¬nh lÃ m vÃ  tháº¥y nÃ³ cÅ©ng ra gÃ¬ ğŸ¤“ğŸ«°. So... Let's dive in! Má»i ngÆ°á»i cÃ³ thá»ƒ tÃ¬m Ä‘Æ°á»£c paper gá»‘c táº¡i [Ä‘Ã¢y](https://arxiv.org/pdf/1406.2661.pdf)

# Giá»›i thiá»‡u


Paper nÃ y náº¿u nhÆ° má»i ngÆ°á»i lá»¥c láº¡i trÃªn arxiv thÃ¬ cÃ³ thá»ƒ tháº¥y nÃ³ Ä‘Æ°á»£c ra vÃ o thÃ¡ng 7 nÄƒm 2014. Theo nhÆ° nháº­n Ä‘á»‹nh cá»§a cÃ¡c tÃ¡c giáº£ vÃ o nÄƒm Ä‘Ã³ thÃ¬ cÃ³ thá»ƒ tháº¥y nhá»¯ng mÃ´ hÃ¬nh deep learning thá»i Ä‘Ã³ **cá»±c thá»‹nh lÃ  nhá»¯ng mÃ´ hÃ¬nh discriminative** (nÃ´m na lÃ  mÃ´ hÃ¬nh phÃ¢n loáº¡i) - lÃ  kiá»ƒu máº¥y cÃ¡i mÃ´ hÃ¬nh, hiá»ƒu Ä‘Æ¡n giáº£n lÃ  hÃ m Ã¡nh xáº¡ tá»« má»™t input cÃ³ sá»‘ chiá»u lá»›n sang má»™t ouput cÃ³ sá»‘ chiá»u nhá» hÆ¡n vÃ  thÆ°á»ng phá»¥c vá»¥ cho bÃ i toÃ¡n phÃ¢n loáº¡i, vÃ­ dá»¥ nhÆ° phÃ¢n loáº¡i chá»¯ sá»‘ viáº¿t tay v.v... 

VÃ  cÅ©ng thá»i Ä‘Ã³, cÃ¡c mÃ´ hÃ¬nh generative (táº¡o sinh) thÃ¬ láº¡i cÃ³ váº» Ã­t sÃ´i ná»•i hÆ¡n (nhÆ°ng giá» thÃ¬ sÃ´i ná»•i rá»“i - 2024). VÃ  cÅ©ng lÃºc nÃ y, cÃ¡c tÃ¡c giáº£ cá»§a paper nÃ y Ä‘Ã£ **propose má»™t framework má»›i**, má»™t framework hoáº¡t Ä‘á»™ng dá»±a trÃªn quÃ¡ trÃ¬nh Ä‘á»‘i ngáº«u (adversarial process - mÃ¬nh sáº½ giáº£i thÃ­ch á»Ÿ phÃ­a dÆ°á»›i). 

**Main Idea**: ChÃºng ta sáº½ huáº¥n luyá»‡n Ä‘á»“ng thá»i 2 mÃ´ hÃ¬nh, má»™t mÃ´ hÃ¬nh táº¡o sinh $G$ vÃ  má»™t mÃ´ hÃ¬nh phÃ¢n loáº¡i $D$. 2 mÃ´ hÃ¬nh nÃ y cÃ³ vai trÃ² khÃ¡c nhau. Äá»‘i vá»›i mÃ´ hÃ¬nh $G$, mÃ´ hÃ¬nh nÃ y sáº½ cá»‘ gáº¯ng **Æ°á»›c lÆ°á»£ng phÃ¢n phá»‘i cá»§a dá»¯ liá»‡u**. Trong khi Ä‘Ã³ Ä‘á»‘i vá»›i mÃ´ hÃ¬nh $D$, nÃ³ sáº½ **phÃ¢n loáº¡i xem má»™t sample nÃ o Ä‘Ã³ lÃ  Ä‘áº¿n tá»« $G$ hay Ä‘áº¿n tá»« bá»™ dá»¯ liá»‡u gá»‘c**. Mong muá»‘n cá»§a mÃ´ hÃ¬nh $G$ Ä‘Ã³ lÃ  cá»±c Ä‘áº¡i kháº£ nÄƒng mÃ´ hÃ¬nh $D$ Ä‘Æ°a ra má»™t káº¿t luáº­n sai (dÃ¢n dÃ£ hÆ¡n lÃ  $G$ pháº£i giá»i tá»›i má»©c mÃ  $D$ khÃ´ng phÃ¡t hiá»‡n Ä‘Æ°á»£c sample Ä‘i ra tá»« $G$ lÃ  giáº£ hay tháº­t). CÃ²n $D$ lÃºc chÃºng ta huáº¥n luyá»‡n thÃ¬ Ä‘Æ°Æ¡ng nhiÃªn lÃºc nÃ o chÃºng ta cÅ©ng muá»‘n $D$ phÃ¢n biá»‡t Ä‘Æ°á»£c rá»“i (dÃ¢n dÃ£ hÆ¡n lÃ  $D$ cÅ©ng pháº£i Ä‘á»§ trÃ¬nh Ä‘á»ƒ lÃºc nÃ o cÅ©ng check var Ä‘Æ°á»£c tháº±ng e $G$). Do Ä‘Ã³ cÃ³ thá»ƒ tháº¥y framework nÃ y lÃ  thuá»™c dáº¡ng minimax two-player game. 

NhÆ° váº­y, thá»© mÃ  chÃºng ta mong muá»‘n trong quÃ¡ trÃ¬nh train (theo lÃ½ thuyáº¿t) lÃ  nhÆ° sau: $G$ cÃ³ thá»ƒ Æ°á»›c lÆ°á»£ng Ä‘Æ°á»£c phÃ¢n phá»‘i cá»§a bá»™ dá»¯ liá»‡u (Æ°á»›c lÆ°á»£ng chÃ­nh xÃ¡c) vÃ  output cá»§a $D$ luÃ´n lÃ  $0.5$. 

# Ã tÆ°á»Ÿng chÃ­nh

Há»“i nÃ y á»Ÿ Ä‘oáº¡n trÃªn mÃ¬nh Ä‘Ã£ cÃ³ Ä‘á» cáº­p vá» cÃ¡i main idea cá»§a cÃ¡i framework nÃ y, bÃ¢y giá» mÃ¬nh sáº½ nÃ³i cá»¥ thá»ƒ hÆ¡n (vá»›i vÃ­ dá»¥ ğŸ‘½).

Giáº£ sá»­ Ä‘ang cÃ³ 2 phe, má»™t phe lÃ m tiá»n giáº£ (Generator ğŸ’µ) vÃ  má»™t phe lÃ m cáº£nh sÃ¡t (Police ğŸ‘®). Phe lÃ m tiá»n giáº£ Ä‘ang cá»‘ gáº¯ng **lÃ m tiá»n giáº£ Ä‘á»ƒ qua máº·t cáº£nh sÃ¡t** vÃ  lÆ°u thÃ´ng lÆ°á»£ng tiá»n giáº£ Ä‘Ã³ ngoÃ i thá»‹ trÆ°á»ng, cÃ²n phe cáº£nh sÃ¡t thÃ¬ láº¡i khÃ´ng muá»‘n lÆ°á»£ng tiá»n giáº£ Ä‘Ã³ lÆ°u thÃ´ng ngoÃ i thá»‹ trÆ°á»ng nÃªn má»›i láº­p **má»™t team Ä‘á»ƒ phÃ¡t hiá»‡n tiá»n giáº£**. Tá»›i Ä‘Ã¢y lÃ  má»i ngÆ°á»i Ä‘Ã£ tháº¥y cÃ³ sá»± Ä‘á»‘i nghá»‹ch vá»›i nhau rá»“i, chá»¯ `Adversarial` cÅ©ng tá»« Ä‘Ã¢y mÃ  ra. 

Giá» vÃ­ dá»¥ cuá»™c Ä‘á»¥ng Ä‘á»™ nÃ y lÃ  dÃ i vÃ´ háº¡n (tá»©c lÃ  náº¿u khÃ´ng cÃ³ gÃ¬ tÃ¡c Ä‘á»™ng thÃ¬ 2 bÃªn váº«n Ä‘Æ¡m nhau). ThÃ¬ á»Ÿ thá»i Ä‘iá»ƒm xuáº¥t phÃ¡t ($t=0$), bÃªn lÃ m tiá»n giáº£ tung ra má»™t lÃ´ tiá»n giáº£, vÃ  cÃ¡c anh cáº£nh sÃ¡t pháº£i gom Ä‘Æ°á»£c cÃ¡i lÃ´ Ä‘Ã³, nhÆ°ng cÃ¡i váº¥n Ä‘á» á»Ÿ Ä‘Ã¢y lÃ  do Ä‘Ã¢y lÃ  láº§n Ä‘áº§u tiÃªn cáº£ 2 lÃ m nhá»¯ng viá»‡c nhÆ° váº­y cho nÃªn há» chÆ°a giá»i. NhÆ° váº­y, sau khi cÃ¡i máº¥y anh cáº£nh sÃ¡t báº¯t Ä‘Æ°á»£c máº¥y lÃ´ tiá»n giáº£, máº¥y anh lÃ m tiá»n giáº£ lÃºc nÃ y má»›i tháº¥y khÃ´ng á»•n, nÃªn lÃ  há» cáº­p nháº­t láº¡i trÃ¬nh Ä‘á»™, rá»“i lÃ m tiá»n giáº£ tá»‘t hÆ¡n. Máº¥y anh cáº£nh sÃ¡t cÅ©ng khÃ´ng chá»‹u Ä‘á»ƒ yÃªn, lÃºc nÃ y máº¥y áº£nh má»›i cáº§m cÃ¡i Ä‘á»‘ng tiá»n giáº£ Ä‘Ã³ Ä‘á»ƒ há»c rá»“i xÃ¡c Ä‘á»‹nh xem cÃ¡i nÃ o má»›i lÃ  giáº£, cÃ¡i nÃ o má»›i lÃ  tháº­t, tá»« Ä‘Ã³ máº¥y áº£nh phÃ¡t hiá»‡n tiá»n giáº£ tá»‘t hÆ¡n. 

VÃ  cá»© nhÆ° váº­y, cho tá»›i má»™t thá»i Ä‘iá»ƒm $t = T$ vá»›i T ráº¥t lá»›n nÃ o Ä‘Ã³, phe lÃ m tiá»n giáº£ Ä‘Ã£ cÃ³ Ä‘á»§ ká»¹ nÄƒng Ä‘á»ƒ lÃ m tiá»n giáº£ y xÃ¬ Ä‘Ãºc tiá»n thiá»‡t, cÃ²n bÃªn cáº£nh sÃ¡t thÃ¬ Ä‘Ã£ Ä‘áº¡t tá»›i giá»›i háº¡n rá»“i, bá»Ÿi vÃ¬ nhÃ¬n tá» tiá»n nÃ o cÅ©ng giá»‘ng nhau (bÃªn tiá»n giáº£ lÃ m tiá»n giáº£ quÃ¡ tá»‘t) nÃªn lÃºc nÃ y, káº¿t quáº£ tiá»n giáº£ vÃ  tiá»n thiá»‡t lÃºc nÃ o cÅ©ng lÃ  50%. 

ToÃ n bá»™ cáº¥u trÃºc cá»§a GAN sáº½ lÃ  nhÆ° sau:

![Source: AWS](/assets/img/blog4/GAN%20architecture.jpg)

BÃ¢y giá» mÃ¬nh sáº½ Ä‘i sÃ¢u hÆ¡n vÃ o tá»«ng thÃ nh pháº§n framework nÃ y.

## Discriminator

Trong GAN thÃ¬ pháº§n discriminator Ä‘Æ¡n giáº£n lÃ  má»™t mÃ´ hÃ¬nh Ä‘á»ƒ phÃ¢n loáº¡i. **Main idea** cá»§a pháº§n nÃ y lÃ  phÃ¢n biá»‡t data tháº­t vÃ  data Ä‘Æ°á»£c táº¡o ra bá»Ÿi pháº§n generator. VÃ  do Ä‘Ã¢y chá»‰ lÃ  cÃ¡i tÃªn thÃ´i, nÃªn vá» cÆ¡ báº£n má»i ngÆ°á»i sá»­ dá»¥ng network nÃ o cÅ©ng Ä‘Æ°á»£c, CNN, MLP, v.v... (trong bÃ i gá»‘c thÃ¬ cÃ¡c tÃ¡c giáº£ chá»n cÃ¡i MLP) miá»…n má»i ngÆ°á»i thiáº¿t káº¿ sao cho nÃ³ thá»±c hiá»‡n Ä‘Æ°á»£c tÃ¡c vá»¥ cá»§a nÃ³ lÃ  ok. 

### Dá»¯ liá»‡u huáº¥n luyá»‡n cá»§a Discriminator

NhÆ° cÃ¡i hÃ¬nh á»Ÿ trÃªn Ä‘Ã£ thá»ƒ hiá»‡n, nguá»“n dá»¯ liá»‡u Ä‘á»ƒ train pháº§n Discriminator Ä‘áº¿n tá»« 2 nguá»“n:
- Dá»¯ liá»‡u tháº­t ($X$): NÃ³ nhÆ° cÃ¡i tÃªn gá»i luÃ´n ._. tá»« chÃ­nh bá»™ dá»¯ liá»‡u tháº­t ğŸ˜
- Dá»¯ liá»‡u giáº£ ($G(\mathbf{Z})$): Dá»¯ liá»‡u nÃ y Ä‘Æ°á»£c sinh ra tá»« pháº§n Generator vá»›i input lÃ  má»™t vector nhiá»…u. 

### QuÃ¡ trÃ¬nh huáº¥n luyá»‡n cá»§a Discriminator

**Trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n Discriminator, chÃºng ta khÃ´ng huáº¥n luyá»‡n pháº§n Generator**. ÄÃ¢y lÃ  má»t Ã½ ráº¥t quan trá»ng, trá»ng sá»‘ cá»§a $G$ Ä‘Æ°á»£c giá»¯ nguyÃªn Ä‘á»ƒ táº¡o sample cho Discriminator huáº¥n luyá»‡n trÃªn Ä‘Ã³. 

NhÆ° trong cÃ¡i hÃ¬nh cá»§a phÃ­a trÃªn, cÃ³ thá»ƒ tháº¥y pháº§n Discriminator liÃªn quan Ä‘áº¿n 2 hÃ m loss chÃ­nh. Trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n Discriminator thÃ¬ nÃ³ sáº½ bá» qua pháº§n loss cá»§a Generator (tá»©c lÃ  nÃ³ chá»‰ dÃ¹ng loss cá»§a nÃ³ thÃ´i). (Má»i ngÆ°á»i lÆ°u Ã½ pháº§n nÃ y bá»Ÿi vÃ¬ huáº¥n luyá»‡n Generator sáº½ hÆ¡i khÃ¡c.)

Trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n pháº§n Discriminator:
1. Pháº§n Discriminator sáº½ phÃ¢n loáº¡i áº£nh tháº­t vÃ  áº£nh giáº£ tá»« cÃ¡c nguá»“n cá»§a nÃ³. 
2. HÃ m loss cá»§a pháº§n Discriminator sáº½ "pháº¡t" pháº§n Discriminator náº¿u nÃ³ phÃ¢n loáº¡i sai (náº¿u nhÆ° sample Ä‘Ã³ lÃ  áº£nh real mÃ  Discriminator kÃªu lÃ  áº£nh fake, vice versa).
3. Pháº§n Discriminator sáº½ tá»± cáº­p nháº­t trá»ng sá»‘ cá»§a nÃ³ thÃ´ng qua lan truyá»n ngÆ°á»£c tá»« cÃ¡i Discriminator loss. 

## Generator

Trong GAN, pháº§n Generator Ä‘Æ°á»£c huáº¥n luyá»‡nd Ä‘á»ƒ táº¡o ra dá»¯ liá»‡u giáº£ báº±ng cÃ¡ch phá»‘i há»£p feedback tá»« discriminator (pháº§n Ã½ tÆ°á»Ÿng mÃ¬nh cÃ³ Ä‘á» cáº­p nhÃ³m trá»™m sáº½ há»c cÃ¡ch lÃ m tiá»n giáº£ tá»‘t hÆ¡n, idea cá»§a tá»« `feedback` trong Ã½ nÃ y cÅ©ng lÃ  cÃ¡i Ä‘Ã³). Objective cá»§a pháº§n Generator lÃ  huáº¥n luyá»‡n sao cho lá»«a Ä‘Æ°á»£c cÃ¡i Discriminator, tá»©c lÃ  lÃ m cho cÃ¡i Discriminator phÃ¢n loáº¡i cÃ¡i hÃ¬nh Ä‘Ã³ lÃ  tháº­t. 

Viá»‡c huáº¥n luyá»‡n Generator cÃ³ nhiá»u yÃªu cáº§u cháº·t cháº½ hÆ¡n khi so vá»›i huáº¥n luyá»‡n pháº§n Discriminator, nÃ³ bao gá»“m cÃ¡c Ã½ dÆ°á»›i Ä‘Ã¢y: ([Google](https://developers.google.com/machine-learning/gan/generator))
- Äáº§u vÃ o ngáº«u nhiÃªn
- Máº¡ng Generator (cÃ¡i gÃ¬ cÅ©ng Ä‘Æ°á»£c, tÃ¡c giáº£ propose dÃ¹ng MLP thuáº§n tÃºy)
- Máº¡ng Discriminator
- Output cá»§a Discriminator
- Generator Loss (idea tÆ°Æ¡ng tá»± nhÆ° hÃ m loss cá»§a Generator, tá»©c lÃ  náº¿u máº¡ng Generator khÃ´ng lá»«a Ä‘Æ°á»£c cÃ¡i Discriminator thÃ¬ nÃ³ sáº½ bá»‹ pháº¡t).

### Äáº§u vÃ o cá»§a Generator

CÃ¡c tÃ¡c giáº£ propose chÃºng ta sá»­ dá»¥ng má»™t cÃ¡i random vector Ä‘á»ƒ lÃ m input cho mÃ´ hÃ¬nh, mÃ  cá»¥ thá»ƒ hÆ¡n, trong paper thÃ¬ cÃ¡c tÃ¡c giáº£ Ä‘á» xuáº¥t cÃ¡c vector nhiá»…u nÃ y sáº½ tuÃ¢n theo phÃ¢n phá»‘i Ä‘á»“ng nháº¥t (Uniform Distribution). Pháº§n Generator sáº½ Ã¡nh xáº¡ cÃ¡i input nÃ y sang má»™t cÃ¡i output cÃ³ Ã½ nghÄ©a, lÃ­ do cho viá»‡c chÃºng ta sá»­ dá»¥ng noise lÃ m input Ä‘Ã³ lÃ  Ä‘á»ƒ GAN cÃ³ thá»ƒ Ä‘a dáº¡ng dá»¯ liá»‡u sinh ra tá»« G hÆ¡n (Ä‘Æ°Æ¡ng nhiÃªn lÃ  váº«n trong cÃ¡i phÃ¢n phá»‘i mÃ  chÃºng ta muá»‘n cÃ¡i Generator tÃ¡i hiá»‡n). 

NhÆ°ng mÃ  theo nhÆ° paper, há» nÃ³i lÃ  cÃ³ nhiá»u thÃ­ nghiá»‡m Ä‘Æ°á»£c thá»±c hiá»‡n vÃ  há» tháº¥y ráº±ng phÃ¢n phá»‘i cá»§a nhiá»…u lÃ  khÃ´ng quan trá»ng láº¯m, nÃªn lÃ  chÃºng ta nÃªn chá»n cÃ¡i gÃ¬ mÃ  chÃºng ta dá»… dÃ ng láº¥y máº«u Ä‘Æ°á»£c, vÃ­ dá»¥ lÃ  láº¥y tá»« má»™t phÃ¢n phá»‘i Ä‘á»“ng nháº¥t. Cá»¥ thá»ƒ hÆ¡n Ã½ mÃ¬nh, goal cá»§a mÃ¬nh lÃ  tÃ¡i hiá»‡n Ä‘Æ°á»£c cÃ¡i phÃ¢n phá»‘i cá»§a bá»™ dá»¯ liá»‡u, tá»©c lÃ  $ \mathbf{x} = G(\mathbf{z})$ lÃ  mong muá»‘n cá»§a mÃ¬nh, nÃªn lÃ  lÃºc nÃ y thÃ¬ $\mathbf{z}$ cÃ³ tuÃ¢n theo phÃ¢n phá»‘i gÃ¬ thÃ¬ sau khi Ã¡nh xáº¡ sang domain cá»§a $\mathbf{x}$ thÃ¬ nÃ³ cÅ©ng khÃ´ng cháº¯c lÃ  sáº½ giá»¯ Ä‘Æ°á»£c cÃ¡i phÃ¢n phá»‘i ban Ä‘áº§u. 

Äiá»u mÃ¬nh vá»«a nÃ³i á»Ÿ trÃªn lÃ  trong cÃ¡i hÃ¬nh nÃ y:

![random_input](/assets/img/blog4/random.png)

VÃ  Ä‘á»ƒ cho thuáº­n tiá»‡n thÃ¬ sá»‘ chiá»u cá»§a cÃ¡i vector nhiá»…u nÃ y thÆ°á»ng nhá» hÆ¡n chiá»u cá»§a output cá»§a mÃ´ hÃ¬nh (vÃ­ dá»¥ trong bÃ i nÃ y, thÃ¬ sá»‘ chiá»u cá»§a vector lÃ  thuá»™c $\mathbb{R}^{100}$, cÃ²n cá»§a output cá»§a Generator lÃ  má»™t cÃ¡i hÃ¬nh thuá»™c $\mathbb{R}^{28 \times 28}$)

### Sá»­ dá»¥ng Discriminator Ä‘á»ƒ huáº¥n luyá»‡n Generator

NhÆ° cÃ¡i hÃ¬nh á»Ÿ trÃªn vá» cáº¥u trÃºc cá»§a GAN, váº¥n Ä‘á» cá»§a cÃ¡i Generator Ä‘Ã³ lÃ  nÃ³ khÃ´ng trá»±c tiáº¿p liÃªn quan tá»›i cÃ¡i hÃ m loss mÃ  chÃºng ta muá»‘n thay Ä‘á»•i (chÃºng ta muá»‘n thay Ä‘á»•i cÃ¡i káº¿t quáº£ output cá»§a cÃ¡i Discriminator), nhÆ°ng mÃ  cÃ¡i Discriminator láº¡i chá»‹u áº£nh hÆ°á»Ÿng cá»§a cÃ¡i Generator. 

VÃ  do Ä‘Ã³, muá»‘n tá»« cÃ¡i output Ä‘Ã³, mÃ  chÃºng ta chá»‰nh láº¡i cÃ¡c tham sá»‘ cá»§a pháº§n Generator, chÃºng ta sáº½ cáº§n pháº£i tÃ­nh thÃªm áº£nh hÆ°á»Ÿng cá»§a cáº£ pháº§n Discriminator. NhÆ° váº­y thÃ¬ quÃ¡ trÃ¬nh lan truyá»n ngÆ°á»£c sáº½ báº¯t Ä‘áº§u tá»« cÃ¡i output vÃ  cháº£y ngÆ°á»£c vá» pháº§n Discriminator, sau Ä‘Ã³ cháº£y ngÆ°á»£c láº¡i vá» pháº§n Generator. VÃ  Ä‘Æ°Æ¡ng nhiÃªn cÅ©ng nhÆ° pháº§n Discriminator, chÃºng ta khÃ´ng muá»‘n Discriminator cÅ©ng bá»‹ cáº­p nháº­t láº¡i tham sá»‘ trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n pháº§n Generator nÃ y, nÃªn chÃºng ta sáº½ freeze nÃ³ láº¡i. 

### QuÃ¡ trÃ¬nh huáº¥n luyá»‡n cá»§a Generator.
1. Láº¥y ngáº«u nhiÃªn má»™t vector nhiá»…u
2. Táº¡o ra output tá»« vector nhiá»…u Ä‘Ã³
3. Pháº§n Discriminator sáº½ xÃ¡c Ä‘á»‹nh tháº­t hay giáº£ tá»« cÃ¡i output vá»«a táº¡o á»Ÿ bÆ°á»›c 2
4. TÃ­nh toÃ¡n loss cá»§a pháº§n Discriminator
5. Lan truyá»n ngÆ°á»£c vá» cáº£ Discriminator vÃ  Generator Ä‘á»ƒ cÃ³ Ä‘Æ°á»£c giÃ¡ trá»‹ gradients
6. Sá»­ dá»¥ng gradient Ä‘á»ƒ thay Ä‘á»•i trá»ng sá»‘ cá»§a cá»§a Generator. 

VÃ  Ä‘Ã³ lÃ  cÃ¡c thá»±c hiá»‡n má»™t vÃ²ng láº·p huáº¥n luyá»‡n cho pháº§n Generator.  


## QuÃ¡ trÃ¬nh huáº¥n luyá»‡n GAN

CÃ³ thá»ƒ tháº¥y GAN cÃ³ 2 thÃ nh pháº§n chÃ­nh á»Ÿ trÃªn vá»›i objective khÃ¡c nhau cÅ©ng nhÆ° cÃ¡ch thá»©c train khÃ¡c nhau, do Ä‘Ã³ khÃ¡ khÃ³ Ä‘á»ƒ cÃ i Ä‘áº·t sao cho phÃ¹ há»£p (cÃ¡c váº¥n Ä‘á» sáº½ Ä‘Æ°á»£c Ä‘á» cáº­p sau) (mÃ  tháº­t ra thÃ¬ cÃ i Ä‘áº·t nhá»¯ng cÃ¡i liÃªn quan Ä‘áº¿n Game Theory thÆ°á»ng khÃ³ ğŸ˜). KhÃ´ng chá»‰ váº­y, sá»± khÃ³ nháº±n cÃ²n náº±m á»Ÿ váº¥n Ä‘á» há»™i tá»¥ cá»§a mÃ´ hÃ¬nh, nÃ³ khÃ´ng Ä‘Æ¡n giáº£n nhÆ° káº¿t quáº£ tá»‘i Æ°u cá»±c Ä‘áº¡i mÃ¬nh Ä‘á» cáº­p á»Ÿ trÃªn ($p_G = p_{data}$ vÃ  $D_G(\mathbf{z}) = 0.5$). 

### PhÆ°Æ¡ng phÃ¡p huáº¥n luyá»‡n GAN

Vá»›i 2 phÆ°Æ¡ng phÃ¡p huáº¥n luyá»‡n khÃ¡c nhau, viá»‡c train toÃ n bá»™ GAN cÃ¹ng má»™t lÃºc cÃ³ thá»ƒ Ä‘Æ°á»£c thay tháº¿ báº±ng quy trÃ¬nh nhÆ° sau:
1. Huáº¥n luyá»‡n Discriminator vá»›i 1 hoáº·c vÃ i epoch
2. Huáº¥n luyá»‡n Generator vá»›i 1 hoáº·c vÃ i epoch
3. Láº·p láº¡i bÆ°á»›c 1 vÃ  bÆ°á»›c 2 tá»›i khi há»™i tá»¥ 

VÃ  pháº£i nhá»› ráº±ng trong lÃºc huáº¥n luyá»‡n 1 thÃ nh pháº§n, ta giá»¯ thÃ nh pháº§n cÃ²n láº¡i cá»‘ Ä‘á»‹nh

### Váº¥n Ä‘á» vá» tÃ­nh há»™i tá»¥

Má»¥c trÃªn cÃ³ Ä‘á» cáº­p vá» váº¥n Ä‘á» cÃ i Ä‘áº·t sao cho phÃ¹ há»£p. CÃ³ thá»ƒ hiá»ƒu ráº±ng pháº§n Generator sáº½ Ä‘Æ°á»£c cáº£i thiá»‡n trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n, vÃ  pháº§n Discriminator sáº½ luÃ´n cÃ³ performance kÃ©m hÆ¡n bá»Ÿi vÃ¬ pháº§n Generator lÃ m tá»‘t hÆ¡n. VÃ  trong trÆ°á»ng há»£p tá»‘i Æ°u toÃ n cá»¥c nhÆ° á»Ÿ trÃªn (generator cho ra output giáº£ trÃ´ng y xÃ¬ real data, cÃ²n discriminator cho ra káº¿t quáº£ nhÆ° Ä‘Ã¡nh gacha) Ä‘Ã£ lÃ²i ra má»™t váº¥n Ä‘á» chÃ­nh khi train tá»•ng thá»ƒ mÃ´ hÃ¬nh GAN.

Váº¥n Ä‘á» náº±m á»Ÿ chá»— pháº§n feedback cá»§a Discriminator trá»Ÿ nÃªn kÃ©m Ã½ nghÄ©a hÆ¡n náº¿u quÃ¡ trÃ¬nh train cá»© tiáº¿p tá»¥c diá»…n ra (bá»Ÿi vÃ¬ nÃ³ khÃ´ng cÃ²n tá»‘t khi so vá»›i pháº§n Generator quÃ¡ siÃªu viá»‡t ná»¯a). VÃ  rá»“i Ä‘áº¿n má»™t lÃºc nÃ o Ä‘Ã³, nhá»¯ng cÃ¡i tÃ­n hiá»‡u pháº£n há»“i cá»§a Discriminator trá»Ÿ nÃªn vÃ´ nghÄ©a (vÃ  cÃ¡i Generator Ä‘Ã³ há»c theo cÃ¡i tÃ­n hiá»‡u vÃ´ nghÄ©a Ä‘Ã³), pháº§n nÃ o Ä‘Ã³ sáº½ lÃ m giáº£m Ä‘i tÃ­nh hiá»‡u quáº£ cá»§a pháº§n Generator. 

Tá»•ng káº¿t láº¡i thÃ¬ quÃ¡ trÃ¬nh huáº¥n luyá»‡n cá»§a GAN cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ³m táº¯t báº±ng hÃ¬nh dÆ°á»›i Ä‘Ã¢y:

![gan_train_process](/assets/img/blog4/train_process.png)

CÃ¡c thÃ nh pháº§n cá»§a hÃ m Loss sáº½ Ä‘Æ°á»£c giáº£i thÃ­ch á»Ÿ phÃ­a dÆ°á»›i. 
## HÃ m Loss
NhÆ° trong cÃ¡i hÃ¬nh Ä‘áº§u tiÃªn, cÃ³ thá»ƒ tháº¥y cÃ³ 2 hÃ m loss, Ã¡m chá»‰ GAN sáº½ sá»­ dá»¥ng 2 hÃ m loss riÃªng biá»‡t. Má»™t hÃ m loss Ä‘Æ°á»£c sá»­ dá»¥ng cho Generator vÃ  má»™t hÃ m loss Ä‘Æ°á»£c sá»­ dá»¥ng cho Discriminator. Quan trá»ng á»Ÿ Ä‘Ã¢y lÃ  2 hÃ m loss nÃ y pháº£i lÃ m viá»‡c cÃ¹ng nhau Ä‘á»ƒ phÃ¡n Ã¡nh Ä‘á»™ Ä‘o vá» khoáº£ng cÃ¡ch cá»§a 2 phÃ¢n phá»‘i xÃ¡c suáº¥t.

Trong paper cá»§a GAN, $D$ vÃ  $G$ Ä‘Ã³ng vai trÃ² lÃ  hay ngÆ°á»i chÆ¡i trong má»™t trÃ² chÆ¡i minimax vá»›i hÃ m giÃ¡ trá»‹ $V(G,D)$ nhÆ° trong cÃ´ng thá»©c sau:

$$
\begin{equation}
V(G,D) = \mathbb{E}_{x \sim p_{data}(x)}[\log D(x)] + \mathbb{E}_{z \sim p_z(z)}[\log (1 - D(G(z)))]
\end{equation}
$$

Trong Ä‘Ã³:
- $D(x)$: Æ¯á»›c lÆ°á»£ng xÃ¡c suáº¥t cá»§a Discriminator cho má»™t dá»¯ liá»‡u tháº­t lÃ  tháº­t. 
- $E_x$: GiÃ¡ trá»‹ ká»³ vá»ng trÃªn toÃ n dá»¯ liá»‡u tháº­t. 
- $G(z)$: Output cá»§a pháº§n Generator vá»›i nhiá»…u z Ä‘Æ°á»£c sampling tá»« $p_z$
- $D(G(z))$: Æ¯á»›c lÆ°á»£ng xÃ¡c suáº¥t cá»§a Discriminator cho má»™t dá»¯ liá»‡u giáº£ lÃ  tháº­t. 
- $E_z$: LÃ  giÃ¡ trá»‹ ká»³ vá»ng trÃªn táº¥t cáº£ input nhiá»…u cá»§a Generator, qua Ä‘Ã³, cÅ©ng lÃ  giÃ¡ trá»‹ ká»³ vá»ng trÃªn toÃ n dá»¯ liá»‡u giáº£ Ä‘Æ°á»£c táº¡o ra tá»« $G(z)$.

Vá»›i cÃ´ng thá»©c á»Ÿ trÃªn, cÃ³ thá»ƒ tháº¥y ráº±ng khÃ´ng cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ pháº§n Generator cÃ³ thá»ƒ áº£nh hÆ°á»Ÿng trá»±c tiáº¿p lÃªn $\log(D(x))$, do Ä‘Ã³ mÃ  vá»›i pháº§n Generator, tá»‘i thiá»ƒu hÃ m loss á»Ÿ trÃªn cÅ©ng Ä‘á»“ng nghÄ©a vá»›i viá»‡c tá»‘i thiá»ƒu $\log (1 - D(G(z)))$ .Tuy nhiÃªn trong thá»±c nghiá»‡m, phÆ°Æ¡ng trÃ¬nh trÃªn khÃ´ng phÃ¹ há»£p cho Ä‘áº¡o hÃ m cá»§a $G$ Ä‘á»ƒ nÃ³ há»c tá»‘t. Bá»Ÿi vÃ¬ thá»­ tÆ°á»Ÿng tÆ°á»£ng, á»Ÿ nhá»¯ng giai Ä‘oáº¡n Ä‘áº§u cá»§a quÃ¡ trÃ¬nh huáº¥n luyá»‡n, nhá»¯ng gÃ¬ $G$ nháº£ ra lÃ  má»™t cÃ¡i output ngáº«u nhiÃªn nÃ o Ä‘Ã³, do Ä‘Ã³ $D$ luÃ´n cÃ³ thá»ƒ dá»… dÃ ng detect Ä‘Æ°á»£c. Trong trÆ°á»ng há»£p nÃ y, $\log (1 - D(G(z)))$ trá»Ÿ nÃªn bÃ£o hÃ²a. Do Ä‘Ã³ mÃ  thay vÃ¬ huáº¥n luyá»‡n $G$ theo cÃ¡i objective á»Ÿ trÃªn, ta cÅ©ng cÃ³ thá»ƒ huáº¥n luyá»‡n $G$ Ä‘á»ƒ tá»‘i Ä‘a giÃ¡ trá»‹ cá»§a $\log(D(G(z)))$. CÃ¡ch thá»©c thay Ä‘á»•i nÃ y cho phÃ©p cung cáº¥p nhiá»u thÃ´ng tin cho $G$ hÆ¡n trong giai Ä‘oáº¡n Ä‘áº§u cá»§a quÃ¡ trÃ¬nh huáº¥n luyá»‡n. 

Cá»¥ thá»ƒ hÆ¡n trong GAN, hÃ m Loss cá»§a Generator vá»›i Ä‘áº§u vÃ o $\mathbf{z}$ lÃ  nhÆ° sau:

$$
\begin{equation}
L_G(\mathbf{z}) = -\log(D(G(\mathbf{z})))
\end{equation}
$$

Trong khi Ä‘Ã³, hÃ m Loss cá»§a Discriminator vá»›i 2 source data khÃ¡c nhau ($\mathbf{z,x}$) lÃ  nhÆ° sau:

$$
\begin{equation}
L_D(\mathbf{z,x}) = -y\log(D(\mathbf{x})) - (1-y)\log(1-D(G(\mathbf{z})))
\end{equation}
$$

# Code

á» Ä‘Ã¢y thÃ¬ mÃ¬nh sáº½ thá»±c hiá»‡n trÃªn bá»™ MNIST (bá»™ nÃ y nháº¹, vÃ  cÃ³ hÃ m Ä‘á»ƒ gá»i tháº³ng luÃ´n). 

Nhá»¯ng cÃ¡i pháº§n nhÆ° lÃ  setup data hay gÃ¬ gÃ¬ Ä‘áº¥y thÃ¬ mÃ¬nh táº¡m bá» qua, mÃ¬nh sáº½ tá»›i nhá»¯ng pháº§n quan trá»ng Ä‘Ã³ lÃ  pháº§n mÃ´ hÃ¬nh vÃ  cÃ¡ch thá»©c huáº¥n luyá»‡n. 

Äáº§u tiÃªn lÃ  cÃ¡ch thiáº¿t káº¿ Generator vÃ  Discriminator. CÃ¡c tÃ¡c giáº£ propose sá»­ dá»¥ng máº¡ng MLP nÃªn mÃ¬nh cÅ©ng sáº½ sá»­ dá»¥ng cÃ¡c máº¡ng MLP. 

```python
class Generator(nn.Module):
    def __init__(self):
        super().__init__()
        self.model = nn.Sequential(
            nn.Linear(latent_dim, 256),
            nn.BatchNorm1d(256,),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Linear(256, 512),
            nn.BatchNorm1d(512),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Linear(512, 1024),
            nn.BatchNorm1d(1024),
            nn.LeakyReLU(0.2, inplace=True),
        
            nn.Linear(1024, int(np.prod(img_shape))),
            nn.Tanh()
        )
        
    def forward(self, z):
        img = self.model(z)
        img = img.view(img.size(0), *img_shape)
        return img
  
class Descriminator(nn.Module):
    def __init__(self):
        super().__init__()
        self.model = nn.Sequential(
            nn.Linear(int(np.prod(img_shape)), 512),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Linear(512, 256),
            nn.LeakyReLU(0.2, inplace=True),
            
            nn.Linear(256, 1),
            nn.Sigmoid()
        )
        
    def forward(self, img):
        img_flat = img.view(img.size(0), -1)
        validity = self.model(img_flat)
        return validity
```
Vá» hÃ m loss thÃ¬ cáº£ 2 thÃ nh pháº§n Ä‘á»u sá»­ dá»¥ng `Binary Cross Entropy Loss`, bÃªn cáº¡nh Ä‘Ã³ thÃ¬ mÃ¬nh sáº½ sá»­ dá»¥ng `Adam Optimizer` (vÃ¬ mÃ¬nh thÃ­ch chá»© trong paper ngÆ°á»i ta dÃ¹ng cÃ¡c phÆ°Æ¡ng phÃ¡p cáº­p nháº­t theo kiá»ƒu gradient-based khÃ¡c, cá»¥ thá»ƒ lÃ  `momentum`). 

```python
EPOCHS = 200
K = 3

optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.0001)
optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002)

criterion = nn.BCELoss()

hist = {
        "train_G_loss": [],
        "train_D_loss": [],
}

for epoch in range(EPOCHS):
    running_G_loss = 0.0
    running_D_loss = 0.0

    for i, (imgs, _) in enumerate(dataloader):

        real_imgs = imgs.to(device)
        real_labels = torch.ones(imgs.shape[0], 1).to(device)
        fake_labels = torch.zeros(imgs.shape[0], 1).to(device)

        # Noise input for Generator
        #z = torch.randn((imgs.shape[0], latent_dim)).to(device)

        # --- Train Discriminator ---
        for step in range(K):
            optimizer_D.zero_grad()
            # Generate a batch of images
            z = torch.randn(imgs.shape[0], latent_dim).to(device)
            fake_imgs = generator(z)
            # Real images
            real_loss = criterion(discriminator(real_imgs), real_labels)
            # Fake images
            fake_loss = criterion(discriminator(fake_imgs), fake_labels)
            # Total loss
            D_loss = (real_loss + fake_loss) / 2
            if step==K-1:
              running_D_loss += D_loss.item()
            else:
              continue
            D_loss.backward()
            optimizer_D.step()
        
        # --- Train Generator --- 
        optimizer_G.zero_grad()
    
        fake_imgs = generator(z)
        G_loss = criterion(discriminator(fake_imgs), real_labels)
        running_G_loss += G_loss.item()

        G_loss.backward()
        optimizer_G.step()

    
    epoch_G_loss = running_G_loss / len(dataloader)
    epoch_D_loss = running_D_loss / len(dataloader)
    
    print(f"Epoch [{epoch + 1}/{EPOCHS}], Train G Loss: {epoch_G_loss:.4f}, Train D Loss: {epoch_D_loss:.4f}")

    hist["train_G_loss"].append(epoch_G_loss)
    hist["train_D_loss"].append(epoch_D_loss)

    if epoch % save_interval == 0:
        save_image(fake_imgs.data[:25], f"images/epoch_{epoch}.png", nrow=5, normalize=True)
```
Trong paper cÃ¡c tÃ¡c giáº£ cÃ³ nÃ³i ráº±ng há» sáº½ sá»­ dá»¥ng $k$ bÆ°á»›c Ä‘á»ƒ tá»‘i Æ°u pháº§n Discriminator vÃ  $1$ bÆ°á»›c Ä‘á»ƒ tá»‘i Æ°u pháº§n Generator (má»—i má»™t minibatch). Äiá»u nÃ y cho phÃ©p cÃ¡c trá»ng sá»‘ cá»§a pháº§n Discriminator náº±m gáº§n káº¿t quáº£ tá»‘i Æ°u (miá»…n lÃ  pháº§n Generator thay Ä‘á»•i tá»« tá»«). VÃ  trong paper, cÃ¡c tÃ¡c giáº£ sá»­ dá»¥ng k = 1. 

# Káº¿t quáº£ thuáº­t toÃ¡n 

Vá»›i bá»™ dá»¯ liá»‡u MNIST khi train trÃªn tá»•ng cá»™ng gáº§n 200 epoch thÃ¬ ta sáº½ cÃ³ nhÆ° sau:

Äáº§u tiÃªn, táº¡i bÆ°á»›c khá»Ÿi táº¡o cá»§a Generator, khi chÃºng ta cho vÃ o input lÃ  má»™t cÃ¡i random vector thÃ¬ output lÃºc nÃ y nhÃ¬n cháº³ng ra cÃ¡i gÃ¬ cáº£, nhÆ° hÃ¬nh dÆ°á»›i Ä‘Ã¢y

![epoch_0](/assets/img/blog4/epoch_0.png){: .align-center}

Sau Ä‘Ã³, train vá»›i khoáº£ng 50 epoch, ta Ä‘Æ°á»£c káº¿t quáº£ nhÆ° dÆ°á»›i Ä‘Ã¢y:

![epoch_50](/assets/img/blog4/epoch_50.png){: .align-center}

VÃ  cuá»‘i cÃ¹ng, train vá»›i khoáº£ng 190 epoch, ta Ä‘Æ°á»£c káº¿t quáº£ nhÆ° hÃ¬nh:

![epoch_190](/assets/img/blog4/epoch_190.png){: .align-center}

VÃ  vá»›i mong Ä‘á»£i cá»§a chÃºng ta, chÃºng ta mong muá»‘n pháº§n Generator cá»§a GAN pháº£i lÃ m tá»‘t, cÅ©ng tá»©c lÃ  giÃ¡ trá»‹ **loss cá»§a Generator pháº£i giáº£m**, nhÆ°ng Ä‘á»“ng thá»i, Ä‘á»ƒ Generator lÃ m tá»‘t, Ä‘á»“ng nghÄ©a vá»›i viá»‡c Discriminator khÃ´ng cÃ²n Ä‘á»§ kháº£ nÄƒng Ä‘á»ƒ ngang hÃ ng vá»›i Generator ná»¯a, cho nÃªn **loss cá»§a Discriminator pháº£i tÄƒng**. Má»i ngÆ°á»i cÃ³ thá»ƒ quan sÃ¡t kÄ© hÆ¡n trong code [nÃ y](https://github.com/ngnquanq/blog/blob/main/Generative%20Adversarial%20Networks/GAN.ipynb). 

VÃ  nhÆ° lÃºc nÃ£y chÃºng ta Ä‘Ã£ Ä‘á» cáº­p, loss cá»§a pháº§n Discriminator, Ä‘áº¹p nháº¥t, nÃªn náº±m á»Ÿ má»©c 0.5 hoáº·c xáº¥p xá»‰, tá»©c lÃ  lÃºc nÃ y, pháº§n Discriminator pháº£i khÃ´ng phÃ¢n biá»‡t Ä‘Æ°á»£c Ä‘Ã¢u lÃ  áº£nh tháº­t, cÃ²n Ä‘Ã¢u lÃ  áº£nh giáº£, lÃºc nÃ y, xÃ¡c suáº¥t Ä‘á»ƒ Discriminator Ä‘Æ°a ra káº¿t quáº£ Ä‘Ãºng khÃ´ng khÃ¡c gÃ¬ trÃ² chÆ¡i may rá»§i. 

Tuy nhiÃªn cÅ©ng pháº£i lÆ°u Ã½ thÃªm, viá»‡c **Ä‘Ã¡nh giÃ¡ GAN báº±ng loss lÃ  chÆ°a Ä‘á»§**. Bá»Ÿi vÃ¬ suy cho cÃ¹ng, ta muá»‘n nhá»¯ng hÃ¬nh áº£nh táº¡o ra bá»Ÿi cÃ¡i Generator má»™t pháº§n nÃ o Ä‘Ã³, pháº£i Ä‘áº¹p ná»¯a, do Ä‘Ã³ mÃ  trong trÆ°á»ng há»£p cá»§a chÃºng ta, loss cÃ³ thá»ƒ lÃ  má»™t thÆ°á»›c Ä‘o chÆ°a phÃ¹ há»£p. 

# Æ¯u vÃ  nhÆ°á»£c Ä‘iá»ƒm cá»§a framework
Æ¯u Ä‘iá»ƒm:
- **Kháº£ nÄƒng há»c khÃ´ng giÃ¡m sÃ¡t**: GANs cÃ³ thá»ƒ há»c Ä‘á»ƒ táº¡o ra dá»¯ liá»‡u mÃ  khÃ´ng cáº§n nhÃ£n, Ä‘iá»u nÃ y má»Ÿ ra kháº£ nÄƒng á»©ng dá»¥ng trong nhiá»u lÄ©nh vá»±c mÃ  dá»¯ liá»‡u cÃ³ nhÃ£n lÃ  khan hiáº¿m.
- **á»¨ng dá»¥ng Ä‘a dáº¡ng**: Tá»« viá»‡c táº¡o áº£nh, video giáº£ máº¡o Ä‘áº¿n viá»‡c táº¡o dá»¯ liá»‡u huáº¥n luyá»‡n cho cÃ¡c mÃ´ hÃ¬nh khÃ¡c, GANs Ä‘Ã£ má»Ÿ ra nhiá»u hÆ°á»›ng á»©ng dá»¥ng má»›i trong AI (nhÆ° mÃ¬nh Ä‘Ã£ nÃ³i, GAN giá»‘ng nhÆ° lÃ  má»™t framework sá»­ dá»¥ng quÃ¡ trÃ¬nh Ä‘á»‘i ngáº«u, chá»© khÃ´ng pháº£i Ä‘Æ¡n thuáº§n chá»‰ lÃ  má»™t máº¡ng nÃ o Ä‘Ã³.)

NhÆ°á»£c Ä‘iá»ƒm:
- **KhÃ³ huáº¥n luyá»‡n**: Viá»‡c cÃ¢n báº±ng giá»¯a mÃ´ hÃ¬nh sinh vÃ  mÃ´ hÃ¬nh phÃ¢n biá»‡t lÃ  má»™t thÃ¡ch thá»©c lá»›n, dá»… dáº«n Ä‘áº¿n tÃ¬nh tráº¡ng mÃ´ hÃ¬nh khÃ´ng há»™i tá»¥. Do Ä‘Ã³ mÃ  chÃºng ta cáº§n pháº£i cÃ¢n nháº¯c tháº­t kÄ© trÆ°á»›c khi Ä‘áº·t tay vÃ o code, bá»Ÿi vÃ¬ nhiá»u tÃ¬nh huá»‘ng cÃ³ thá»ƒ xáº£y ra nhÆ° mÃ¬nh nÃ³i á»Ÿ trÃªn (vÃ­ dá»¥ nhÆ° Discriminator thá»‘ng trá»‹ luÃ´n pháº§n Generator)
- **Mode collapse**: ÄÃ¢y lÃ  hiá»‡n tÆ°á»£ng mÃ  mÃ´ hÃ¬nh sinh chá»‰ táº¡o ra má»™t sá»‘ lÆ°á»£ng háº¡n cháº¿ cÃ¡c máº«u, lÃ m giáº£m Ä‘a dáº¡ng cá»§a dá»¯ liá»‡u Ä‘Æ°á»£c táº¡o ra. Má»i ngÆ°á»i cÃ³ thá»ƒ tháº¥y Ä‘iá»u nÃ y trong epoch thá»© 190 á»Ÿ trÃªn, cÃ¡c tham sá»‘ cá»§a Generator Ä‘Ã£ há»™i tá»¥ á»Ÿ nÆ¡i mÃ  nÃ³ lá»«a Ä‘Æ°á»£c Discriminator, vÃ  vá» má»™t má»©c Ä‘á»™ nÃ o Ä‘Ã³ thÃ¬ káº¿t quáº£ Ä‘Ã³ an toÃ n, nhÆ°ng nháº¡t. 


# Tháº£o luáº­n thÃªm. 
Vá» pháº§n tháº£o luáº­n thÃªm, cÃ¡c tÃ¡c giáº£ cÃ³ Ä‘á» xuáº¥t trong paper rá»“i nÃªn mÃ¬nh cÅ©ng khÃ´ng biáº¿t nÃ³i gÃ¬ ._.  NhÆ°ng cÃ¡ nhÃ¢n mÃ¬nh tháº¥y káº¿t há»£p game theory vÃ o deep learning cÅ©ng ráº¥t sÃ¡ng táº¡o =)))))))))))) nÃ³i chung lÃ  há»©ng thÃº. 

Cháº¯c cÅ©ng pháº£i kiáº¿m thÃªm vÃ i cÃ¡i Ä‘á»ƒ cÃ i láº¡i cho Ä‘á»¡ chÃ¡n : D

# Reference

1: AWS - [https://aws.amazon.com/vi/what-is/gan/](https://aws.amazon.com/vi/what-is/gan/)

2: Google - [https://developers.google.com/machine-learning/gan/generator](https://developers.google.com/machine-learning/gan/generator)

3: AIO